{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import requests\n",
      "from httpcache import CachingHTTPAdapter\n",
      "import json\n",
      "import os\n",
      "import pickle\n",
      "from time import sleep\n",
      "\n",
      "# You might be running elasticsearch in a vagrant box\n",
      "esUrl = elasticSearchUrl = \"http://es:9200\"\n",
      "\n",
      "# you'll need to have an API key for TMDB\n",
      "# to run these examples,\n",
      "# run export TMDB_API_KEY=<YourAPIKey>\n",
      "tmdb_api_key = os.environ[\"TMDB_API_KEY\"]\n",
      "\n",
      "# Setup tmdb as its own session, caching requests\n",
      "# (we only want to cache tmdb, not elasticsearch)\n",
      "tmdb_api = requests.Session()\n",
      "tmdb_api.mount('https://', CachingHTTPAdapter())\n",
      "tmdb_api.mount('http://', CachingHTTPAdapter())\n",
      "tmdb_api.params={'api_key': tmdb_api_key}\n",
      "\n",
      "# Some utilities for flattening the explain into something a bit more\n",
      "# readable\n",
      "def flatten(l):\n",
      "    [item for sublist in l for item in sublist]\n",
      "\n",
      "def simplerExplain(explainJson, depth=0):\n",
      "    result = \" \" * (depth * 2) + \"%s, %s\\n\" % (explainJson['value'], explainJson['description'])\n",
      "    #print json.dumps(explainJson, indent=True)\n",
      "    if 'details' in explainJson:\n",
      "        for detail in explainJson['details']:\n",
      "            result += simplerExplain(detail, depth=depth+1)\n",
      "    return result"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 29
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here we crawl top rated movies from TMDB and pull out a list of of top rated ids"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "movieIds = [];\n",
      "numMoviesToGrab = 10000\n",
      "numPages = numMoviesToGrab / 20\n",
      "\n",
      "for page in range(1, numPages + 1):\n",
      "    httpResp = tmdb_api.get('https://api.themoviedb.org/3/movie/top_rated', params={'page': page})  #(1)\n",
      "    jsonResponse = json.loads(httpResp.text) #(2)\n",
      "    movies = jsonResponse['results']\n",
      "    for movie in movies:\n",
      "        if (movie['id'] not in [9549]):\n",
      "            movieIds.append(movie['id'])\n",
      "print len(movieIds)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2884\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/home/doug/workspace/taming-search-book/scraps/venv/lib/python2.7/site-packages/requests/packages/urllib3/util/ssl_.py:79: InsecurePlatformWarning: A true SSLContext object is not available. This prevents urllib3 from configuring SSL appropriately and may cause certain SSL connections to fail. For more information, see https://urllib3.readthedocs.org/en/latest/security.html#insecureplatformwarning.\n",
        "  InsecurePlatformWarning\n"
       ]
      }
     ],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "movieDict = {}\n",
      "for movieId in movieIds:\n",
      "    httpResp = tmdb_api.get(\"https://api.themoviedb.org/3/movie/%s\" % movieId)\n",
      "    movie = json.loads(httpResp.text)\n",
      "    movieDict[movieId] = movie"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Destroy any existing index (equiv to SQL \"drop table\")\n",
      "resp = requests.delete(elasticSearchUrl + \"/tmdb\")\n",
      "print resp.status_code\n",
      "\n",
      "# Create the index with explicit settings\n",
      "# We need to explicitely set number of shards to 1 to eliminate the impact of \n",
      "# distributed IDF on our small collection\n",
      "# See also \"Relavance is Broken!\"\n",
      "# http://www.elastic.co/guide/en/elasticsearch/guide/current/relevance-is-broken.html\n",
      "settings = {\n",
      "    \"settings\": {\"number_of_shards\": 1}\n",
      "}\n",
      "resp = requests.put(elasticSearchUrl + \"/tmdb\", data=json.dumps(settings))\n",
      "print resp.status_code\n",
      "\n",
      "# Bulk index title & overview to the movie endpoint\n",
      "print \"Indexing %i movies\" % len(movieDict.keys())\n",
      "bulkMovies = \"\"\n",
      "for id, movie in movieDict.iteritems():\n",
      "    addCmd = {\"index\": {\"_index\": \"tmdb\", \"_type\": \"movie\", \"_id\": movie[\"id\"]}}\n",
      "    esDoc  = {\"title\": movie['title'], 'overview': movie['overview'], 'tagline': movie['tagline']}\n",
      "    bulkMovies += json.dumps(addCmd) + \"\\n\" + json.dumps(esDoc) + \"\\n\"\n",
      "requests.post(elasticSearchUrl + \"/_bulk\", data=bulkMovies)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "200\n",
        "200\n",
        "Indexing 2879 movies\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 32,
       "text": [
        "<Response [200]>"
       ]
      }
     ],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Execute a fairly basic search\n",
      "# Where many may start, obviously title matches are important, but our\n",
      "# body field (overview) also should get a great deal of weight\n",
      "# \n",
      "# PROBLEM\n",
      "#  This query is replete with problems\n",
      "#   - with probably should be a stopword (yet it causes the title results with 'with') to shoot to the top\n",
      "#   - even after fixing this, we see that dismax \"winner takes all\" creates problems\n",
      "# \n",
      "#\n",
      "# Multi Match notes\n",
      "#   starts out like dismax\n",
      "#   type dictates how dismax is handled\n",
      "#    - default best_fields is winner takes all problems with dismax\n",
      "#    - most_fields (like dismax with tie always set to 1 -- Doug's favorite)\n",
      "#       Every field gets a vote\n",
      "#    - cross fields (unique to ES)\n",
      "#\n",
      "usersSearch = 'basketball with cartoon aliens'\n",
      "search = {\n",
      "    'query': {\n",
      "        'multi_match': { \n",
      "            'query': usersSearch,  #User's query\n",
      "            'fields': ['title^10', 'overview'],\n",
      "        }\n",
      "    },\n",
      "    'size': '100',\n",
      "    'explain': True\n",
      "}\n",
      "\n",
      "httpResp = requests.get(elasticSearchUrl + '/tmdb/movie/_search', data=json.dumps(search))\n",
      "searchHits = json.loads(httpResp.text)['hits']\n",
      "print \"Num\\tRelevance Score\\t\\tMovie Title\\t\\tOverview\"\n",
      "for idx, hit in enumerate(searchHits['hits']):\n",
      "        print \"%s\\t%s\\t\\t%s\\t\\t%s\" % (idx + 1, hit['_score'], hit['_source']['title'], len(hit['_source']['overview']))\n",
      "\n",
      "for idx, hit in enumerate(searchHits['hits']):\n",
      "    if hit['_source']['title'] == 'Aliens' or hit['_source']['title'] == 'Space Jam':\n",
      "        print \"Explain for %s\" % hit['_source']['title']\n",
      "        print simplerExplain(hit['_explanation'])\n",
      "    \n",
      "    \n",
      "# print searchHits['hits'][0]['_source']['overview']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Num\tRelevance Score\t\tMovie Title\t\tOverview\n",
        "1\t1.0643067\t\tAlien\t\t420\n",
        "2\t1.0643067\t\tAliens\t\t357\n",
        "3\t1.0643067\t\tAlien\u00b3\t\t380\n",
        "4\t1.0254613\t\tThe Basketball Diaries\t\t131\n",
        "5\t0.66519165\t\tCowboys & Aliens\t\t367\n",
        "6\t0.66519165\t\tAliens in the Attic\t\t617\n",
        "7\t0.66519165\t\tAlien: Resurrection\t\t260\n",
        "8\t0.53215337\t\tAliens vs Predator: Requiem\t\t481\n",
        "9\t0.53215337\t\tAVP: Alien vs. Predator\t\t344\n",
        "10\t0.53215337\t\tMonsters vs Aliens\t\t333\n",
        "11\t0.08334568\t\tSpace Jam\t\t119\n",
        "12\t0.02486766\t\tGrown Ups\t\t138\n",
        "13\t0.023184514\t\tThe Flintstones\t\t280\n",
        "14\t0.023184514\t\tSpeed Racer\t\t280\n",
        "15\t0.021315135\t\tWhite Men Can't Jump\t\t221\n",
        "16\t0.021315135\t\tCoach Carter\t\t171\n",
        "17\t0.01845945\t\tSemi-Pro\t\t740\n",
        "18\t0.016565826\t\tThe Thing\t\t125\n",
        "19\t0.01421009\t\tHigh School Musical\t\t435\n",
        "20\t0.01421009\t\tBedazzled\t\t326\n",
        "21\t0.014056569\t\tMeet Dave\t\t191\n",
        "22\t0.01325266\t\tEscape from Planet Earth\t\t127\n",
        "23\t0.01325266\t\tThe Darkest Hour\t\t98\n",
        "24\t0.01325266\t\tInvasion of the Body Snatchers\t\t114\n",
        "25\t0.01325266\t\tSlither\t\t111\n",
        "26\t0.011713807\t\tDistrict 9\t\t328\n",
        "27\t0.011596078\t\tAvatar\t\t175\n",
        "28\t0.011596078\t\tThe Last Starfighter\t\t147\n",
        "29\t0.010042498\t\tThe X Files\t\t708\n",
        "30\t0.009939495\t\tNapoleon Dynamite\t\t184\n",
        "31\t0.009939495\t\tThe Day the Earth Stood Still\t\t183\n",
        "32\t0.009939495\t\tGalaxy Quest\t\t230\n",
        "33\t0.009939495\t\tOutlander\t\t213\n",
        "34\t0.009939495\t\tScary Movie 3\t\t216\n",
        "35\t0.009939495\t\tTitan A.E.\t\t179\n",
        "36\t0.009939495\t\tThe Hitchhiker's Guide to the Galaxy\t\t222\n",
        "37\t0.009371046\t\tStar Trek IV: The Voyage Home\t\t573\n",
        "38\t0.009371046\t\tIndependence Day\t\t393\n",
        "39\t0.009371046\t\tGhosts of Mars\t\t539\n",
        "40\t0.009371046\t\tDude, Where\u2019s My Car?\t\t398\n",
        "41\t0.009371046\t\tEdge of Tomorrow\t\t371\n",
        "42\t0.008282913\t\tContact\t\t252\n",
        "43\t0.008282913\t\tStar Trek: Insurrection\t\t277\n",
        "44\t0.008282913\t\tPredators\t\t321\n",
        "45\t0.008282913\t\tMars Attacks!\t\t289\n",
        "46\t0.008282913\t\tPitch Black\t\t361\n",
        "47\t0.008282913\t\tBatteries Not Included\t\t249\n",
        "48\t0.008282913\t\tLifted\t\t320\n",
        "49\t0.008282913\t\tScary Movie 4\t\t224\n",
        "50\t0.008282913\t\tJustice League: War\t\t272\n",
        "51\t0.008282913\t\tThe Watch\t\t313\n",
        "52\t0.008282913\t\tSpecies\t\t327\n",
        "53\t0.008282913\t\tThe Host\t\t239\n",
        "54\t0.008282913\t\tUnder the Skin\t\t249\n",
        "55\t0.008199665\t\tAttack the Block\t\t533\n",
        "56\t0.008199665\t\tBattleship\t\t606\n",
        "57\t0.00662633\t\tPredator\t\t465\n",
        "58\t0.00662633\t\tPredator 2\t\t407\n",
        "59\t0.00662633\t\tMen in Black\t\t503\n",
        "60\t0.00662633\t\tThey Live\t\t427\n",
        "61\t0.00662633\t\tBattlefield Earth\t\t394\n",
        "62\t0.00662633\t\tThe Faculty\t\t441\n",
        "63\t0.00662633\t\tThe Day the Earth Stood Still\t\t350\n",
        "64\t0.00662633\t\tShort Circuit\t\t349\n",
        "65\t0.00662633\t\tMonsters\t\t479\n",
        "66\t0.00662633\t\tLilo & Stitch\t\t305\n",
        "67\t0.00662633\t\tSpider-Man 3\t\t357\n",
        "68\t0.00662633\t\tDoom\t\t459\n",
        "69\t0.00662633\t\tHalo 4: Forward Unto Dawn\t\t580\n",
        "70\t0.00662633\t\tThe Invasion\t\t451\n",
        "71\t0.00662633\t\tRiddick\t\t471\n",
        "72\t0.00662633\t\tDreamcatcher\t\t413\n",
        "73\t0.00662633\t\tSpring Breakers\t\t536\n",
        "74\t0.00662633\t\tPaul\t\t431\n",
        "75\t0.005798039\t\tMen in Black II\t\t634\n",
        "76\t0.005798039\t\tMen in Black 3\t\t572\n",
        "77\t0.005798039\t\tPride\t\t673\n",
        "78\t0.005798039\t\tMars Needs Moms\t\t537\n",
        "79\t0.005798039\t\tThere Will Be Blood\t\t633\n",
        "80\t0.0049697473\t\tStalker\t\t755\n",
        "81\t0.0049697473\t\tWreck-It Ralph\t\t658\n",
        "Explain for Aliens\n",
        "1.0643067, max of:\n",
        "  1.0643067, product of:\n",
        "    3.19292, sum of:\n",
        "      3.19292, weight(title:alien in 435) [PerFieldSimilarity], result of:\n",
        "        3.19292, score(doc=435,freq=1.0 = termFreq=1.0\n",
        "), product of:\n",
        "          0.4793294, queryWeight, product of:\n",
        "            6.661223, idf(docFreq=9, maxDocs=2875)\n",
        "            0.07195817, queryNorm\n",
        "          6.661223, fieldWeight in 435, product of:\n",
        "            1.0, tf(freq=1.0), with freq of:\n",
        "              1.0, termFreq=1.0\n",
        "            6.661223, idf(docFreq=9, maxDocs=2875)\n",
        "            1.0, fieldNorm(doc=435)\n",
        "    0.33333334, coord(1/3)\n",
        "  0.008282913, product of:\n",
        "    0.024848737, sum of:\n",
        "      0.024848737, weight(overview:alien in 435) [PerFieldSimilarity], result of:\n",
        "        0.024848737, score(doc=435,freq=1.0 = termFreq=1.0\n",
        "), product of:\n",
        "          0.03382846, queryWeight, product of:\n",
        "            4.701128, idf(docFreq=70, maxDocs=2875)\n",
        "            0.0071958173, queryNorm\n",
        "          0.73455125, fieldWeight in 435, product of:\n",
        "            1.0, tf(freq=1.0), with freq of:\n",
        "              1.0, termFreq=1.0\n",
        "            4.701128, idf(docFreq=70, maxDocs=2875)\n",
        "            0.15625, fieldNorm(doc=435)\n",
        "    0.33333334, coord(1/3)\n",
        "\n",
        "Explain for Space Jam\n",
        "0.08334568, max of:\n",
        "  0.08334568, product of:\n",
        "    0.12501852, sum of:\n",
        "      0.08526054, weight(overview:basketbal in 1289) [PerFieldSimilarity], result of:\n",
        "        0.08526054, score(doc=1289,freq=1.0 = termFreq=1.0\n",
        "), product of:\n",
        "          0.049538642, queryWeight, product of:\n",
        "            6.8843665, idf(docFreq=7, maxDocs=2875)\n",
        "            0.0071958173, queryNorm\n",
        "          1.7210916, fieldWeight in 1289, product of:\n",
        "            1.0, tf(freq=1.0), with freq of:\n",
        "              1.0, termFreq=1.0\n",
        "            6.8843665, idf(docFreq=7, maxDocs=2875)\n",
        "            0.25, fieldNorm(doc=1289)\n",
        "      0.03975798, weight(overview:alien in 1289) [PerFieldSimilarity], result of:\n",
        "        0.03975798, score(doc=1289,freq=1.0 = termFreq=1.0\n",
        "), product of:\n",
        "          0.03382846, queryWeight, product of:\n",
        "            4.701128, idf(docFreq=70, maxDocs=2875)\n",
        "            0.0071958173, queryNorm\n",
        "          1.175282, fieldWeight in 1289, product of:\n",
        "            1.0, tf(freq=1.0), with freq of:\n",
        "              1.0, termFreq=1.0\n",
        "            4.701128, idf(docFreq=70, maxDocs=2875)\n",
        "            0.25, fieldNorm(doc=1289)\n",
        "    0.6666667, coord(2/3)\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Inner Layer of the Onion -- Why did the search engine consider these movies matches? Two sides to this\n",
      "# (1) What tokens are placed in the search engine?\n",
      "# (2) What did the search engine attempt to match exactly?\n",
      "\n",
      "# Explain of what's happening when we construct these terms\n",
      "\n",
      "#resp = requests.get(elasticSearchUrl + \"/tmdb/_mapping/movie/field/title?format=yaml'\n",
      "resp = requests.get(elasticSearchUrl + '/tmdb/_analyze?analyzer=standard&format=yaml', \n",
      "                    data=\"Fire with Fire\")\n",
      "print resp.text"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "---\n",
        "tokens:\n",
        "- token: \"fire\"\n",
        "  start_offset: 0\n",
        "  end_offset: 4\n",
        "  type: \"<ALPHANUM>\"\n",
        "  position: 1\n",
        "- token: \"with\"\n",
        "  start_offset: 5\n",
        "  end_offset: 9\n",
        "  type: \"<ALPHANUM>\"\n",
        "  position: 2\n",
        "- token: \"fire\"\n",
        "  start_offset: 10\n",
        "  end_offset: 14\n",
        "  type: \"<ALPHANUM>\"\n",
        "  position: 3\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Explain what's happening behind the scenes in this multimatch query\n",
      "\n",
      "just_search = {\n",
      "   'query': search['query']\n",
      "}\n",
      "httpResp = requests.get(elasticSearchUrl + '/tmdb/movie/_validate/query?explain', data=json.dumps(just_search))\n",
      "json.loads(httpResp.text)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 18,
       "text": [
        "{u'_shards': {u'failed': 0, u'successful': 1, u'total': 1},\n",
        " u'explanations': [{u'explanation': u'filtered((((title:basketbal title:cartoon title:alien)^10.0) | (overview:basketbal overview:cartoon overview:alien)))->cache(_type:movie)',\n",
        "   u'index': u'tmdb',\n",
        "   u'valid': True}],\n",
        " u'valid': True}"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# The explain shows us there is a clear problem with ambigous terms\n",
      "# What is one way to solve this?\n",
      "#  - We have a genre field we could introduce\n",
      "#  - Can we curate a set of synonyms (ie 'space exploration') as synonymous with\n",
      "#    a particular genre?\n",
      "\n",
      "search['explain'] = True\n",
      "httpResp = requests.get(elasticSearchUrl + '/tmdb/movie/_search', data=json.dumps(search))\n",
      "jsonResp = json.loads(httpResp.text)\n",
      "print json.dumps(jsonResp['hits']['hits'][0]['_explanation'], indent=True)\n",
      "print \"Explain for %s\" % jsonResp['hits']['hits'][0]['_source']['title']\n",
      "print simplerExplain(jsonResp['hits']['hits'][0]['_explanation'])\n",
      "print \"Explain for %s\" % jsonResp['hits']['hits'][1]['_source']['title']\n",
      "print simplerExplain(jsonResp['hits']['hits'][1]['_explanation'])\n",
      "print \"Explain for %s\" % jsonResp['hits']['hits'][2]['_source']['title']\n",
      "print simplerExplain(jsonResp['hits']['hits'][2]['_explanation'])\n",
      "print \"Explain for %s\" % jsonResp['hits']['hits'][3]['_source']['title']\n",
      "print simplerExplain(jsonResp['hits']['hits'][3]['_explanation'])\n",
      "print \"Explain for %s\" % jsonResp['hits']['hits'][10]['_source']['title']\n",
      "print simplerExplain(jsonResp['hits']['hits'][10]['_explanation'])\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{\n",
        " \"description\": \"max of:\", \n",
        " \"value\": 1.0643067, \n",
        " \"details\": [\n",
        "  {\n",
        "   \"description\": \"product of:\", \n",
        "   \"value\": 1.0643067, \n",
        "   \"details\": [\n",
        "    {\n",
        "     \"description\": \"sum of:\", \n",
        "     \"value\": 3.19292, \n",
        "     \"details\": [\n",
        "      {\n",
        "       \"description\": \"weight(title:alien in 223) [PerFieldSimilarity], result of:\", \n",
        "       \"value\": 3.19292, \n",
        "       \"details\": [\n",
        "        {\n",
        "         \"description\": \"score(doc=223,freq=1.0 = termFreq=1.0\\n), product of:\", \n",
        "         \"value\": 3.19292, \n",
        "         \"details\": [\n",
        "          {\n",
        "           \"description\": \"queryWeight, product of:\", \n",
        "           \"value\": 0.4793294, \n",
        "           \"details\": [\n",
        "            {\n",
        "             \"description\": \"idf(docFreq=9, maxDocs=2875)\", \n",
        "             \"value\": 6.661223\n",
        "            }, \n",
        "            {\n",
        "             \"description\": \"queryNorm\", \n",
        "             \"value\": 0.07195817\n",
        "            }\n",
        "           ]\n",
        "          }, \n",
        "          {\n",
        "           \"description\": \"fieldWeight in 223, product of:\", \n",
        "           \"value\": 6.661223, \n",
        "           \"details\": [\n",
        "            {\n",
        "             \"description\": \"tf(freq=1.0), with freq of:\", \n",
        "             \"value\": 1.0, \n",
        "             \"details\": [\n",
        "              {\n",
        "               \"description\": \"termFreq=1.0\", \n",
        "               \"value\": 1.0\n",
        "              }\n",
        "             ]\n",
        "            }, \n",
        "            {\n",
        "             \"description\": \"idf(docFreq=9, maxDocs=2875)\", \n",
        "             \"value\": 6.661223\n",
        "            }, \n",
        "            {\n",
        "             \"description\": \"fieldNorm(doc=223)\", \n",
        "             \"value\": 1.0\n",
        "            }\n",
        "           ]\n",
        "          }\n",
        "         ]\n",
        "        }\n",
        "       ]\n",
        "      }\n",
        "     ]\n",
        "    }, \n",
        "    {\n",
        "     \"description\": \"coord(1/3)\", \n",
        "     \"value\": 0.33333334\n",
        "    }\n",
        "   ]\n",
        "  }, \n",
        "  {\n",
        "   \"description\": \"product of:\", \n",
        "   \"value\": 0.00662633, \n",
        "   \"details\": [\n",
        "    {\n",
        "     \"description\": \"sum of:\", \n",
        "     \"value\": 0.01987899, \n",
        "     \"details\": [\n",
        "      {\n",
        "       \"description\": \"weight(overview:alien in 223) [PerFieldSimilarity], result of:\", \n",
        "       \"value\": 0.01987899, \n",
        "       \"details\": [\n",
        "        {\n",
        "         \"description\": \"score(doc=223,freq=1.0 = termFreq=1.0\\n), product of:\", \n",
        "         \"value\": 0.01987899, \n",
        "         \"details\": [\n",
        "          {\n",
        "           \"description\": \"queryWeight, product of:\", \n",
        "           \"value\": 0.03382846, \n",
        "           \"details\": [\n",
        "            {\n",
        "             \"description\": \"idf(docFreq=70, maxDocs=2875)\", \n",
        "             \"value\": 4.701128\n",
        "            }, \n",
        "            {\n",
        "             \"description\": \"queryNorm\", \n",
        "             \"value\": 0.0071958173\n",
        "            }\n",
        "           ]\n",
        "          }, \n",
        "          {\n",
        "           \"description\": \"fieldWeight in 223, product of:\", \n",
        "           \"value\": 0.587641, \n",
        "           \"details\": [\n",
        "            {\n",
        "             \"description\": \"tf(freq=1.0), with freq of:\", \n",
        "             \"value\": 1.0, \n",
        "             \"details\": [\n",
        "              {\n",
        "               \"description\": \"termFreq=1.0\", \n",
        "               \"value\": 1.0\n",
        "              }\n",
        "             ]\n",
        "            }, \n",
        "            {\n",
        "             \"description\": \"idf(docFreq=70, maxDocs=2875)\", \n",
        "             \"value\": 4.701128\n",
        "            }, \n",
        "            {\n",
        "             \"description\": \"fieldNorm(doc=223)\", \n",
        "             \"value\": 0.125\n",
        "            }\n",
        "           ]\n",
        "          }\n",
        "         ]\n",
        "        }\n",
        "       ]\n",
        "      }\n",
        "     ]\n",
        "    }, \n",
        "    {\n",
        "     \"description\": \"coord(1/3)\", \n",
        "     \"value\": 0.33333334\n",
        "    }\n",
        "   ]\n",
        "  }\n",
        " ]\n",
        "}\n",
        "Explain for Alien\n",
        "1.0643067, max of:\n",
        "  1.0643067, product of:\n",
        "    3.19292, sum of:\n",
        "      3.19292, weight(title:alien in 223) [PerFieldSimilarity], result of:\n",
        "        3.19292, score(doc=223,freq=1.0 = termFreq=1.0\n",
        "), product of:\n",
        "          0.4793294, queryWeight, product of:\n",
        "            6.661223, idf(docFreq=9, maxDocs=2875)\n",
        "            0.07195817, queryNorm\n",
        "          6.661223, fieldWeight in 223, product of:\n",
        "            1.0, tf(freq=1.0), with freq of:\n",
        "              1.0, termFreq=1.0\n",
        "            6.661223, idf(docFreq=9, maxDocs=2875)\n",
        "            1.0, fieldNorm(doc=223)\n",
        "    0.33333334, coord(1/3)\n",
        "  0.00662633, product of:\n",
        "    0.01987899, sum of:\n",
        "      0.01987899, weight(overview:alien in 223) [PerFieldSimilarity], result of:\n",
        "        0.01987899, score(doc=223,freq=1.0 = termFreq=1.0\n",
        "), product of:\n",
        "          0.03382846, queryWeight, product of:\n",
        "            4.701128, idf(docFreq=70, maxDocs=2875)\n",
        "            0.0071958173, queryNorm\n",
        "          0.587641, fieldWeight in 223, product of:\n",
        "            1.0, tf(freq=1.0), with freq of:\n",
        "              1.0, termFreq=1.0\n",
        "            4.701128, idf(docFreq=70, maxDocs=2875)\n",
        "            0.125, fieldNorm(doc=223)\n",
        "    0.33333334, coord(1/3)\n",
        "\n",
        "Explain for Aliens\n",
        "1.0643067, max of:\n",
        "  1.0643067, product of:\n",
        "    3.19292, sum of:\n",
        "      3.19292, weight(title:alien in 435) [PerFieldSimilarity], result of:\n",
        "        3.19292, score(doc=435,freq=1.0 = termFreq=1.0\n",
        "), product of:\n",
        "          0.4793294, queryWeight, product of:\n",
        "            6.661223, idf(docFreq=9, maxDocs=2875)\n",
        "            0.07195817, queryNorm\n",
        "          6.661223, fieldWeight in 435, product of:\n",
        "            1.0, tf(freq=1.0), with freq of:\n",
        "              1.0, termFreq=1.0\n",
        "            6.661223, idf(docFreq=9, maxDocs=2875)\n",
        "            1.0, fieldNorm(doc=435)\n",
        "    0.33333334, coord(1/3)\n",
        "  0.008282913, product of:\n",
        "    0.024848737, sum of:\n",
        "      0.024848737, weight(overview:alien in 435) [PerFieldSimilarity], result of:\n",
        "        0.024848737, score(doc=435,freq=1.0 = termFreq=1.0\n",
        "), product of:\n",
        "          0.03382846, queryWeight, product of:\n",
        "            4.701128, idf(docFreq=70, maxDocs=2875)\n",
        "            0.0071958173, queryNorm\n",
        "          0.73455125, fieldWeight in 435, product of:\n",
        "            1.0, tf(freq=1.0), with freq of:\n",
        "              1.0, termFreq=1.0\n",
        "            4.701128, idf(docFreq=70, maxDocs=2875)\n",
        "            0.15625, fieldNorm(doc=435)\n",
        "    0.33333334, coord(1/3)\n",
        "\n",
        "Explain for Alien\u00b3\n",
        "1.0643067, max of:\n",
        "  1.0643067, product of:\n",
        "    3.19292, sum of:\n",
        "      3.19292, weight(title:alien in 2855) [PerFieldSimilarity], result of:\n",
        "        3.19292, score(doc=2855,freq=1.0 = termFreq=1.0\n",
        "), product of:\n",
        "          0.4793294, queryWeight, product of:\n",
        "            6.661223, idf(docFreq=9, maxDocs=2875)\n",
        "            0.07195817, queryNorm\n",
        "          6.661223, fieldWeight in 2855, product of:\n",
        "            1.0, tf(freq=1.0), with freq of:\n",
        "              1.0, termFreq=1.0\n",
        "            6.661223, idf(docFreq=9, maxDocs=2875)\n",
        "            1.0, fieldNorm(doc=2855)\n",
        "    0.33333334, coord(1/3)\n",
        "  0.00662633, product of:\n",
        "    0.01987899, sum of:\n",
        "      0.01987899, weight(overview:alien in 2855) [PerFieldSimilarity], result of:\n",
        "        0.01987899, score(doc=2855,freq=1.0 = termFreq=1.0\n",
        "), product of:\n",
        "          0.03382846, queryWeight, product of:\n",
        "            4.701128, idf(docFreq=70, maxDocs=2875)\n",
        "            0.0071958173, queryNorm\n",
        "          0.587641, fieldWeight in 2855, product of:\n",
        "            1.0, tf(freq=1.0), with freq of:\n",
        "              1.0, termFreq=1.0\n",
        "            4.701128, idf(docFreq=70, maxDocs=2875)\n",
        "            0.125, fieldNorm(doc=2855)\n",
        "    0.33333334, coord(1/3)\n",
        "\n",
        "Explain for The Basketball Diaries\n",
        "1.0254613, max of:\n",
        "  1.0254613, product of:\n",
        "    3.0763838, sum of:\n",
        "      3.0763838, weight(title:basketbal in 1278) [PerFieldSimilarity], result of:\n",
        "        3.0763838, score(doc=1278,freq=1.0 = termFreq=1.0\n",
        "), product of:\n",
        "          0.5951416, queryWeight, product of:\n",
        "            8.27066, idf(docFreq=1, maxDocs=2875)\n",
        "            0.07195817, queryNorm\n",
        "          5.1691628, fieldWeight in 1278, product of:\n",
        "            1.0, tf(freq=1.0), with freq of:\n",
        "              1.0, termFreq=1.0\n",
        "            8.27066, idf(docFreq=1, maxDocs=2875)\n",
        "            0.625, fieldNorm(doc=1278)\n",
        "    0.33333334, coord(1/3)\n",
        "\n",
        "Explain for Space Jam\n",
        "0.08334568, max of:\n",
        "  0.08334568, product of:\n",
        "    0.12501852, sum of:\n",
        "      0.08526054, weight(overview:basketbal in 1289) [PerFieldSimilarity], result of:\n",
        "        0.08526054, score(doc=1289,freq=1.0 = termFreq=1.0\n",
        "), product of:\n",
        "          0.049538642, queryWeight, product of:\n",
        "            6.8843665, idf(docFreq=7, maxDocs=2875)\n",
        "            0.0071958173, queryNorm\n",
        "          1.7210916, fieldWeight in 1289, product of:\n",
        "            1.0, tf(freq=1.0), with freq of:\n",
        "              1.0, termFreq=1.0\n",
        "            6.8843665, idf(docFreq=7, maxDocs=2875)\n",
        "            0.25, fieldNorm(doc=1289)\n",
        "      0.03975798, weight(overview:alien in 1289) [PerFieldSimilarity], result of:\n",
        "        0.03975798, score(doc=1289,freq=1.0 = termFreq=1.0\n",
        "), product of:\n",
        "          0.03382846, queryWeight, product of:\n",
        "            4.701128, idf(docFreq=70, maxDocs=2875)\n",
        "            0.0071958173, queryNorm\n",
        "          1.175282, fieldWeight in 1289, product of:\n",
        "            1.0, tf(freq=1.0), with freq of:\n",
        "              1.0, termFreq=1.0\n",
        "            4.701128, idf(docFreq=70, maxDocs=2875)\n",
        "            0.25, fieldNorm(doc=1289)\n",
        "    0.6666667, coord(2/3)\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "---\n",
        "tmdb:\n",
        "  settings:\n",
        "    index:\n",
        "      creation_date: \"1423513692064\"\n",
        "      uuid: \"m8A_tI3gSi6QBG-6fZsUBQ\"\n",
        "      number_of_replicas: \"1\"\n",
        "      number_of_shards: \"5\"\n",
        "      version:\n",
        "        created: \"1040299\"\n",
        "\n",
        "---\n",
        "tmdb:\n",
        "  mappings:\n",
        "    movie:\n",
        "      title:\n",
        "        full_name: \"title\"\n",
        "        mapping:\n",
        "          title:\n",
        "            type: \"string\"\n",
        "\n",
        "---\n",
        "tokens:\n",
        "- token: \"the\"\n",
        "  start_offset: 0\n",
        "  end_offset: 3\n",
        "  type: \"<ALPHANUM>\"\n",
        "  position: 1\n",
        "- token: \"lego\"\n",
        "  start_offset: 4\n",
        "  end_offset: 8\n",
        "  type: \"<ALPHANUM>\"\n",
        "  position: 2\n",
        "- token: \"movie\"\n",
        "  start_offset: 9\n",
        "  end_offset: 14\n",
        "  type: \"<ALPHANUM>\"\n",
        "  position: 3\n",
        "- token: \"an\"\n",
        "  start_offset: 15\n",
        "  end_offset: 17\n",
        "  type: \"<ALPHANUM>\"\n",
        "  position: 4\n",
        "- token: \"ordinary\"\n",
        "  start_offset: 18\n",
        "  end_offset: 26\n",
        "  type: \"<ALPHANUM>\"\n",
        "  position: 5\n",
        "- token: \"lego\"\n",
        "  start_offset: 27\n",
        "  end_offset: 31\n",
        "  type: \"<ALPHANUM>\"\n",
        "  position: 6\n",
        "- token: \"mini\"\n",
        "  start_offset: 32\n",
        "  end_offset: 36\n",
        "  type: \"<ALPHANUM>\"\n",
        "  position: 7\n",
        "- token: \"figure\"\n",
        "  start_offset: 37\n",
        "  end_offset: 43\n",
        "  type: \"<ALPHANUM>\"\n",
        "  position: 8\n",
        "- token: \"mistakenly\"\n",
        "  start_offset: 45\n",
        "  end_offset: 55\n",
        "  type: \"<ALPHANUM>\"\n",
        "  position: 9\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Removing Domain-Specific Stopwords"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To reduce the impact of the movie term, one thing we can try is to list movie itself as a stopword. A stopword is a term considered noise. It tends corresponds to an absense of meaning. Articles like \"the\" and prepositions like \"of\" are common candidates in most English stopwords lists. Usually stopwords are known for their very high document frequency and therefore low impact on the score. So we often don't need to do anything to the stopwords.\n",
      "\n",
      "However, occasionally we encounter domain-specific stopwords so obvious that they are often omitted from the text. We saw this for the \"movie\" term above. The feature of \"movieness\" is heavily implied, and not at all reflected in the text. These scenarios are particularly true for shorter snippets of text where brevity rules the day. Much of our current text is rather short, so our movie search suffers from these problems.\n",
      "\n",
      "We need to express to the search engine that the term \"movie\" should be removed from the index. To do this, we need to create a custom analyzer, using the current standard analyzer as its basis. We'll then assign the `_all` field to this analyzer via the mapping API."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "requests.delete(esUrl + '/tmdb')\n",
      "\n",
      "settings = {\n",
      "    'settings': {\n",
      "        \"number_of_shards\": 1,\n",
      "    },\n",
      "    'mappings': {\n",
      "            'movie': {\n",
      "                'properties': {\n",
      "                    'title': {\n",
      "                        'type': 'string',\n",
      "                        'analyzer': 'english'\n",
      "                    },\n",
      "                    'overview': {\n",
      "                        'type': 'string',\n",
      "                        'analyzer': 'english'\n",
      "                    }\n",
      "                }\n",
      "                \n",
      "            }\n",
      "       }\n",
      "    \n",
      "}\n",
      "\n",
      "#requests.post(esUrl + \"/tmdb/_close\")\n",
      "resp = requests.put(esUrl + '/tmdb/', data=json.dumps(settings))\n",
      "print resp.text\n",
      "sleep(1)\n",
      "\n",
      "\n",
      "resp = requests.get(esUrl + '/tmdb/_mappings?format=yaml')\n",
      "print resp.text\n",
      "#requests.post(esUrl + \"/tmdb/_open\")\n",
      "print resp.text\n",
      "# Wait for index to open\n",
      "\n",
      "sleep(1)\n",
      "\n",
      "# Reindex\n",
      "resp = requests.post(elasticSearchUrl + \"/_bulk\", data=bulkMovies)\n",
      "\n",
      "resp = requests.get(elasticSearchUrl + '/tmdb/_analyze?field=title&format=yaml', \n",
      "                    data=\"Fire with Fire\")\n",
      "print resp.text\n",
      "\n",
      "resp = requests.get(elasticSearchUrl + '/tmdb/_refresh')\n",
      "print resp.text\n",
      "\n",
      "sleep(1)\n",
      "\n",
      "httpResp = requests.get(elasticSearchUrl + '/tmdb/movie/_search', data=json.dumps(search))\n",
      "searchHits = json.loads(httpResp.text)['hits']\n",
      "\n",
      "print \"Num\\tRelevance Score\\t\\tMovie Title\\t\\tOverview\"\n",
      "for idx, hit in enumerate(searchHits['hits']):\n",
      "        print \"%s\\t%s\\t\\t%s\\t\\t%s\" % (idx + 1, hit['_score'], hit['_source']['title'], len(hit['_source']['overview']))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{\"acknowledged\":true}\n",
        "---\n",
        "tmdb:\n",
        "  mappings:\n",
        "    movie:\n",
        "      properties:\n",
        "        overview:\n",
        "          type: \"string\"\n",
        "          analyzer: \"english\"\n",
        "        title:\n",
        "          type: \"string\"\n",
        "          analyzer: \"english\"\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "---\n",
        "tmdb:\n",
        "  mappings:\n",
        "    movie:\n",
        "      properties:\n",
        "        overview:\n",
        "          type: \"string\"\n",
        "          analyzer: \"english\"\n",
        "        title:\n",
        "          type: \"string\"\n",
        "          analyzer: \"english\"\n",
        "\n",
        "---\n",
        "tokens:\n",
        "- token: \"fire\"\n",
        "  start_offset: 0\n",
        "  end_offset: 4\n",
        "  type: \"<ALPHANUM>\"\n",
        "  position: 1\n",
        "- token: \"fire\"\n",
        "  start_offset: 10\n",
        "  end_offset: 14\n",
        "  type: \"<ALPHANUM>\"\n",
        "  position: 3\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "{\"_shards\":{\"total\":2,\"successful\":1,\"failed\":0}}"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Num\tRelevance Score\t\tMovie Title\t\tOverview"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "1\t1.0643067\t\tAlien\t\t420\n",
        "2\t1.0643067\t\tAliens\t\t357\n",
        "3\t1.0643067\t\tAlien\u00b3\t\t380\n",
        "4\t1.0254613\t\tThe Basketball Diaries\t\t131\n",
        "5\t0.66519165\t\tCowboys & Aliens\t\t367\n",
        "6\t0.66519165\t\tAliens in the Attic\t\t617\n",
        "7\t0.66519165\t\tAlien: Resurrection\t\t260\n",
        "8\t0.53215337\t\tAliens vs Predator: Requiem\t\t481\n",
        "9\t0.53215337\t\tAVP: Alien vs. Predator\t\t344\n",
        "10\t0.53215337\t\tMonsters vs Aliens\t\t333\n",
        "11\t0.08334568\t\tSpace Jam\t\t119\n",
        "12\t0.02486766\t\tGrown Ups\t\t138\n",
        "13\t0.023184514\t\tThe Flintstones\t\t280\n",
        "14\t0.023184514\t\tSpeed Racer\t\t280\n",
        "15\t0.021315135\t\tWhite Men Can't Jump\t\t221\n",
        "16\t0.021315135\t\tCoach Carter\t\t171\n",
        "17\t0.01845945\t\tSemi-Pro\t\t740\n",
        "18\t0.016565826\t\tThe Thing\t\t125\n",
        "19\t0.01421009\t\tHigh School Musical\t\t435\n",
        "20\t0.01421009\t\tBedazzled\t\t326\n",
        "21\t0.014056569\t\tMeet Dave\t\t191\n",
        "22\t0.01325266\t\tEscape from Planet Earth\t\t127\n",
        "23\t0.01325266\t\tThe Darkest Hour\t\t98\n",
        "24\t0.01325266\t\tInvasion of the Body Snatchers\t\t114\n",
        "25\t0.01325266\t\tSlither\t\t111\n",
        "26\t0.011713807\t\tDistrict 9\t\t328\n",
        "27\t0.011596078\t\tAvatar\t\t175\n",
        "28\t0.011596078\t\tThe Last Starfighter\t\t147\n",
        "29\t0.010042498\t\tThe X Files\t\t708\n",
        "30\t0.009939495\t\tNapoleon Dynamite\t\t184\n",
        "31\t0.009939495\t\tThe Day the Earth Stood Still\t\t183\n",
        "32\t0.009939495\t\tGalaxy Quest\t\t230\n",
        "33\t0.009939495\t\tOutlander\t\t213\n",
        "34\t0.009939495\t\tScary Movie 3\t\t216\n",
        "35\t0.009939495\t\tTitan A.E.\t\t179\n",
        "36\t0.009939495\t\tThe Hitchhiker's Guide to the Galaxy\t\t222\n",
        "37\t0.009371046\t\tStar Trek IV: The Voyage Home\t\t573\n",
        "38\t0.009371046\t\tIndependence Day\t\t393\n",
        "39\t0.009371046\t\tGhosts of Mars\t\t539\n",
        "40\t0.009371046\t\tDude, Where\u2019s My Car?\t\t398\n",
        "41\t0.009371046\t\tEdge of Tomorrow\t\t371\n",
        "42\t0.008282913\t\tContact\t\t252\n",
        "43\t0.008282913\t\tStar Trek: Insurrection\t\t277\n",
        "44\t0.008282913\t\tPredators\t\t321\n",
        "45\t0.008282913\t\tMars Attacks!\t\t289\n",
        "46\t0.008282913\t\tPitch Black\t\t361\n",
        "47\t0.008282913\t\tBatteries Not Included\t\t249\n",
        "48\t0.008282913\t\tLifted\t\t320\n",
        "49\t0.008282913\t\tScary Movie 4\t\t224\n",
        "50\t0.008282913\t\tJustice League: War\t\t272\n",
        "51\t0.008282913\t\tThe Watch\t\t313\n",
        "52\t0.008282913\t\tSpecies\t\t327\n",
        "53\t0.008282913\t\tThe Host\t\t239\n",
        "54\t0.008282913\t\tUnder the Skin\t\t249\n",
        "55\t0.008199665\t\tAttack the Block\t\t533\n",
        "56\t0.008199665\t\tBattleship\t\t606\n",
        "57\t0.00662633\t\tPredator\t\t465\n",
        "58\t0.00662633\t\tPredator 2\t\t407\n",
        "59\t0.00662633\t\tMen in Black\t\t503\n",
        "60\t0.00662633\t\tThey Live\t\t427\n",
        "61\t0.00662633\t\tBattlefield Earth\t\t394\n",
        "62\t0.00662633\t\tThe Faculty\t\t441\n",
        "63\t0.00662633\t\tThe Day the Earth Stood Still\t\t350\n",
        "64\t0.00662633\t\tShort Circuit\t\t349\n",
        "65\t0.00662633\t\tMonsters\t\t479\n",
        "66\t0.00662633\t\tLilo & Stitch\t\t305\n",
        "67\t0.00662633\t\tSpider-Man 3\t\t357\n",
        "68\t0.00662633\t\tDoom\t\t459\n",
        "69\t0.00662633\t\tHalo 4: Forward Unto Dawn\t\t580\n",
        "70\t0.00662633\t\tThe Invasion\t\t451\n",
        "71\t0.00662633\t\tRiddick\t\t471\n",
        "72\t0.00662633\t\tDreamcatcher\t\t413\n",
        "73\t0.00662633\t\tSpring Breakers\t\t536\n",
        "74\t0.00662633\t\tPaul\t\t431\n",
        "75\t0.005798039\t\tMen in Black II\t\t634\n",
        "76\t0.005798039\t\tMen in Black 3\t\t572\n",
        "77\t0.005798039\t\tPride\t\t673\n",
        "78\t0.005798039\t\tMars Needs Moms\t\t537\n",
        "79\t0.005798039\t\tThere Will Be Blood\t\t633\n",
        "80\t0.0049697473\t\tStalker\t\t755\n",
        "81\t0.0049697473\t\tWreck-It Ralph\t\t658\n"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}