{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import requests\n",
      "\n",
      "# Some utilities for flattening the explain into something a bit more\n",
      "# readable. Pass Explain JSON, get something readable (ironically this is what Solr's default output is :-p)\n",
      "def flatten(l):\n",
      "    [item for sublist in l for item in sublist]\n",
      "\n",
      "def simplerExplain(explainJson, depth=0):\n",
      "    result = \" \" * (depth * 2) + \"%s, %s\\n\" % (explainJson['value'], explainJson['description'])\n",
      "    #print json.dumps(explainJson, indent=True)\n",
      "    if 'details' in explainJson:\n",
      "        for detail in explainJson['details']:\n",
      "            result += simplerExplain(detail, depth=depth+1)\n",
      "    return result"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "4.2.2"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "settings = {\n",
      "  \"settings\": {\n",
      "    \"analysis\": {\n",
      "      \"analyzer\": {\n",
      "        \"standard_clone\": {\n",
      "          \"tokenizer\": \"standard\",\n",
      "          \"filter\": [\n",
      "            \"standard\",\n",
      "            \"lowercase\",\n",
      "            \"stop \"]}}}}}\n",
      "\n",
      "requests.delete(\"http://localhost:9200/my_library\")\n",
      "requests.put(\"http://localhost:9200/my_library\", data=json.dumps(settings))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 82,
       "text": [
        "<Response [200]>"
       ]
      }
     ],
     "prompt_number": 82
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "resp = requests.get(\"http://localhost:9200/my_library/_analyze?analyzer=standard_clone\", \n",
      "                    data=\"Dr. Strangelove: Or How I Learned to Stop Worrying and Love the Bomb\")\n",
      "resp = json.loads(resp.text)\n",
      "\",\".join(['[' + token['token'] + ']'  for token in resp['tokens']])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 97,
       "text": [
        "u'[dr],[strangelove],[how],[i],[learned],[stop],[worrying],[love],[bomb]'"
       ]
      }
     ],
     "prompt_number": 97
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "resp = requests.get(\"http://localhost:9200/my_library/_analyze?analyzer=standard_clone\", \n",
      "                    data=\"mr. weirdlove: don't worry, I'm learning to start loving bombs\")\n",
      "resp = json.loads(resp.text)\n",
      "\",\".join(['[' + token['token'] + ']'  for token in resp['tokens']])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 98,
       "text": [
        "u\"[mr],[weirdlove],[don't],[worry],[i'm],[learning],[start],[loving],[bombs]\""
       ]
      }
     ],
     "prompt_number": 98
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Create a stub keywords.txt at /tmp\n",
      "keywordsPath = \"/tmp/keywords.txt\";\n",
      "import os\n",
      "if os.name == \"nt\":\n",
      "    keywordsPath = \"C:\\\\temp\\keywords.txt\"\n",
      "\n",
      "f = open(\"/tmp/keywords.txt\", \"w\")\n",
      "f.write(\"maine\\n\")\n",
      "f.close()\n",
      "\n",
      "settings = {\n",
      "  \"settings\": {\n",
      "    \"analysis\": {\n",
      "      \"filter\": {\n",
      "        \"english_stop\": {\n",
      "          \"type\":       \"stop\",\n",
      "          \"stopwords\":  \"_english_\"},\n",
      "        \"english_keywords\": {\n",
      "          \"type\":       \"keyword_marker\",\n",
      "          \"keywords_path\":   keywordsPath},\n",
      "        \"english_stemmer\": {\n",
      "          \"type\":       \"stemmer\",\n",
      "          \"language\":   \"english\"},\n",
      "        \"english_possessive_stemmer\": {\n",
      "          \"type\":       \"stemmer\",\n",
      "          \"language\":   \"possessive_english\"}},\n",
      "      \"analyzer\": {\n",
      "        \"english_clone\": {\n",
      "          \"tokenizer\":  \"standard\",\n",
      "          \"filter\": [\n",
      "            \"standard\",  \n",
      "            \"english_possessive_stemmer\",\n",
      "            \"lowercase\",\n",
      "            \"english_stop\",\n",
      "            \"english_keywords\",\n",
      "            \"english_stemmer\"]}}}}}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 113
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "requests.delete(\"http://localhost:9200/my_library\")\n",
      "requests.put(\"http://localhost:9200/my_library\", data=json.dumps(settings)).text"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 114,
       "text": [
        "u'{\"acknowledged\":true}'"
       ]
      }
     ],
     "prompt_number": 114
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "resp = requests.get(\"http://localhost:9200/my_library/_analyze?analyzer=english_clone\", \n",
      "                    data=\"flowers flower flowered flower\")\n",
      "resp = json.loads(resp.text)\n",
      "\",\".join(['[' + token['token'] + ']'  for token in resp['tokens']])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 115,
       "text": [
        "u'[flower],[flower],[flower],[flower]'"
       ]
      }
     ],
     "prompt_number": 115
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "resp = requests.get(\"http://localhost:9200/my_library/_analyze?analyzer=english_clone\", \n",
      "                    data=\"silly silliness sillied sillying\")\n",
      "resp = json.loads(resp.text)\n",
      "\",\".join(['[' + token['token'] + ']'  for token in resp['tokens']])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 116,
       "text": [
        "u'[silli],[silli],[silli],[silli]'"
       ]
      }
     ],
     "prompt_number": 116
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "resp = requests.get(\"http://localhost:9200/my_library/_analyze?analyzer=english_clone\", \n",
      "                    data=\"maine main\")\n",
      "resp = json.loads(resp.text)\n",
      "\",\".join(['[' + token['token'] + ']'  for token in resp['tokens']])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 117,
       "text": [
        "u'[maine],[main]'"
       ]
      }
     ],
     "prompt_number": 117
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "resp = requests.get(\"http://localhost:9200/my_library/_analyze?analyzer=english_clone\", \n",
      "                    data=\"Dr. Strangelove: Or How I Learned to Stop Worrying and Love the Bomb\")\n",
      "resp = json.loads(resp.text)\n",
      "\",\".join(['[' + token['token'] + ']'  for token in resp['tokens']])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 118,
       "text": [
        "u'[dr],[strangelov],[how],[i],[learn],[stop],[worri],[love],[bomb]'"
       ]
      }
     ],
     "prompt_number": 118
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "resp = requests.get(\"http://localhost:9200/my_library/_analyze?analyzer=english_clone\", \n",
      "                    data=\"mr. weirdlove: don't worry, I'm learning to start loving bombs\")\n",
      "resp = json.loads(resp.text)\n",
      "\",\".join(['[' + token['token'] + ']'  for token in resp['tokens']])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 119,
       "text": [
        "u\"[mr],[weirdlov],[don't],[worri],[i'm],[learn],[start],[love],[bomb]\""
       ]
      }
     ],
     "prompt_number": 119
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "4.2.3"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Requires phonetic analysis plugin \n",
      "# https://www.elastic.co/guide/en/elasticsearch/plugins/2.1/analysis-phonetic.html\n",
      "#\n",
      "# To install on *nix systems\n",
      "# 1. Navigate to Elasticsearc directory\n",
      "# cd /usr/share/elasticsearch\n",
      "# 2. sudo bin/plugin install analysis-phonetic"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 128
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "settings = { \"settings\": {\n",
      "    \"analysis\": {\n",
      "      \"analyzer\": {\n",
      "        \"phonetic\": {\n",
      "          \"tokenizer\": \"standard\",\n",
      "          \"filter\": [\n",
      "            \"standard\",\n",
      "            \"lowercase\",\n",
      "            \"my_doublemetaphone\"]}},\n",
      "      \"filter\": {\n",
      "        \"my_doublemetaphone\": {\n",
      "          \"type\": \"phonetic\",\n",
      "          \"encoder\": \"doublemetaphone\", \n",
      "          \"replace\": True}}}}}\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 130
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "requests.delete(\"http://localhost:9200/my_library\")\n",
      "requests.put(\"http://localhost:9200/my_library\", data=json.dumps(settings)).text"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 131,
       "text": [
        "u'{\"acknowledged\":true}'"
       ]
      }
     ],
     "prompt_number": 131
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "resp = requests.get(\"http://localhost:9200/my_library/_analyze?analyzer=phonetic\", \n",
      "                    data=\"message from Dalai Lama\")\n",
      "resp = json.loads(resp.text)\n",
      "\",\".join(['[' + token['token'] + ']'  for token in resp['tokens']])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 133,
       "text": [
        "u'[MSJ],[MSK],[FRM],[TL],[LM]'"
       ]
      }
     ],
     "prompt_number": 133
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "resp = requests.get(\"http://localhost:9200/my_library/_analyze?analyzer=phonetic\", \n",
      "                    data=\"massage from tall llama\")\n",
      "resp = json.loads(resp.text)\n",
      "\",\".join(['[' + token['token'] + ']'  for token in resp['tokens']])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 134,
       "text": [
        "u'[MSJ],[MSK],[FRM],[TL],[LM]'"
       ]
      }
     ],
     "prompt_number": 134
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "4.3.1"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import json\n",
      "requests.delete(\"http://localhost:9200/my_library\")\n",
      "\n",
      "settings = {\"settings\": \n",
      "    {\"number_of_shards\": 1}}\n",
      "\n",
      "requests.put(\"http://localhost:9200/my_library\", data=json.dumps(settings))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "<Response [200]>"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import json\n",
      "\n",
      "documents = [\n",
      "{ \"title\":\"apple apple apple apple apple\"},\n",
      "{ \"title\":\"apple apple apple banana banana\"},\n",
      "{ \"title\":\"apple banana blueberry coconut\"},\n",
      "]\n",
      "\n",
      "for idx, document in enumerate(documents):\n",
      "    URL = \"http://localhost:9200/my_library/example/%s\" % (idx + 1)\n",
      "    print URL\n",
      "    print document\n",
      "    resp = requests.put(URL, data=json.dumps(document))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "http://localhost:9200/my_library/example/1\n",
        "{'title': 'apple apple apple apple apple'}\n",
        "http://localhost:9200/my_library/example/2\n",
        "{'title': 'apple apple apple banana banana'}\n",
        "http://localhost:9200/my_library/example/3"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "{'title': 'apple banana blueberry coconut'}\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "search = { \"explain\": \"true\",\n",
      "  \"query\": {\n",
      "    \"match\": {\n",
      "      \"title\": \"apple\"}}}\n",
      "\n",
      "resp = requests.get(\"http://localhost:9200/my_library/example/_search?pretty=true\", data=json.dumps(search))\n",
      "respJson = json.loads(resp.text)\n",
      "for idx, hit in enumerate(respJson['hits']['hits']):\n",
      "    print (\"%s.  \" % (idx + 1)) + repr(hit['_source'])\n",
      "    print simplerExplain(hit['_explanation'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1.  {u'title': u'apple apple apple apple apple'}\n",
        "0.6968462, sum of:\n",
        "  0.6968462, weight(title:apple in 0) [PerFieldSimilarity], result of:\n",
        "    0.6968462, fieldWeight in 0, product of:\n",
        "      2.236068, tf(freq=5.0), with freq of:\n",
        "        5.0, termFreq=5.0\n",
        "      0.71231794, idf(docFreq=3, maxDocs=3)\n",
        "      0.4375, fieldNorm(doc=0)\n",
        "  0.0, match on required clause, product of:\n",
        "    0.0, # clause\n",
        "    1.4038675, _type:example, product of:\n",
        "      1.0, boost\n",
        "      1.4038675, queryNorm\n",
        "\n",
        "2.  {u'title': u'apple apple apple banana banana'}\n",
        "0.5397748, sum of:\n",
        "  0.5397748, weight(title:apple in 1) [PerFieldSimilarity], result of:\n",
        "    0.5397748, fieldWeight in 1, product of:\n",
        "      1.7320508, tf(freq=3.0), with freq of:\n",
        "        3.0, termFreq=3.0\n",
        "      0.71231794, idf(docFreq=3, maxDocs=3)\n",
        "      0.4375, fieldNorm(doc=1)\n",
        "  0.0, match on required clause, product of:\n",
        "    0.0, # clause\n",
        "    1.4038675, _type:example, product of:\n",
        "      1.0, boost\n",
        "      1.4038675, queryNorm\n",
        "\n",
        "3.  {u'title': u'apple banana blueberry coconut'}\n",
        "0.35615897, sum of:\n",
        "  0.35615897, weight(title:apple in 2) [PerFieldSimilarity], result of:\n",
        "    0.35615897, fieldWeight in 2, product of:\n",
        "      1.0, tf(freq=1.0), with freq of:\n",
        "        1.0, termFreq=1.0\n",
        "      0.71231794, idf(docFreq=3, maxDocs=3)\n",
        "      0.5, fieldNorm(doc=2)\n",
        "  0.0, match on required clause, product of:\n",
        "    0.0, # clause\n",
        "    1.4038675, _type:example, product of:\n",
        "      1.0, boost\n",
        "      1.4038675, queryNorm\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "extraDoc = { \"title\":\"apples apple\"}\n",
      "resp = requests.put(\"http://localhost:9200/my_library/example/%s\" % (5), data=json.dumps(extraDoc))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "resp = requests.get(\"http://localhost:9200/my_library/example/_search?pretty=true\", data=json.dumps(search))\n",
      "respJson = json.loads(resp.text)\n",
      "for idx, hit in enumerate(respJson['hits']['hits']):\n",
      "    print (\"%s.  \" % (idx + 1)) + repr(hit['_source'])\n",
      "    print simplerExplain(hit['_explanation'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1.  {u'title': u'apple apple apple apple apple'}\n",
        "0.6968462, sum of:\n",
        "  0.6968462, weight(title:apple in 0) [PerFieldSimilarity], result of:\n",
        "    0.6968462, fieldWeight in 0, product of:\n",
        "      2.236068, tf(freq=5.0), with freq of:\n",
        "        5.0, termFreq=5.0\n",
        "      0.71231794, idf(docFreq=3, maxDocs=3)\n",
        "      0.4375, fieldNorm(doc=0)\n",
        "  0.0, match on required clause, product of:\n",
        "    0.0, # clause\n",
        "    1.4038675, _type:example, product of:\n",
        "      1.0, boost\n",
        "      1.4038675, queryNorm\n",
        "\n",
        "2.  {u'title': u'apple apple apple banana banana'}\n",
        "0.5397748, sum of:\n",
        "  0.5397748, weight(title:apple in 1) [PerFieldSimilarity], result of:\n",
        "    0.5397748, fieldWeight in 1, product of:\n",
        "      1.7320508, tf(freq=3.0), with freq of:\n",
        "        3.0, termFreq=3.0\n",
        "      0.71231794, idf(docFreq=3, maxDocs=3)\n",
        "      0.4375, fieldNorm(doc=1)\n",
        "  0.0, match on required clause, product of:\n",
        "    0.0, # clause\n",
        "    1.4038675, _type:example, product of:\n",
        "      1.0, boost\n",
        "      1.4038675, queryNorm\n",
        "\n",
        "3.  {u'title': u'apple banana blueberry coconut'}\n",
        "0.35615897, sum of:\n",
        "  0.35615897, weight(title:apple in 2) [PerFieldSimilarity], result of:\n",
        "    0.35615897, fieldWeight in 2, product of:\n",
        "      1.0, tf(freq=1.0), with freq of:\n",
        "        1.0, termFreq=1.0\n",
        "      0.71231794, idf(docFreq=3, maxDocs=3)\n",
        "      0.5, fieldNorm(doc=2)\n",
        "  0.0, match on required clause, product of:\n",
        "    0.0, # clause\n",
        "    1.4038675, _type:example, product of:\n",
        "      1.0, boost\n",
        "      1.4038675, queryNorm\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "requests.delete(\"http://localhost:9200/my_library\")\n",
      "\n",
      "settings = {\"settings\": \n",
      "    {\"number_of_shards\": 1, \n",
      "     \"index\": \n",
      "         {\"analysis\": {\n",
      "            \"analyzer\": {\n",
      "              \"default\": {\n",
      "                \"type\": \"english\"\n",
      "             \n",
      "    }}}}}\n",
      "}\n",
      "\n",
      "resp = requests.put(\"http://localhost:9200/my_library\", data=json.dumps(settings))\n",
      "print resp.text"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{\"acknowledged\":true}\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "documents.append(extraDoc)\n",
      "\n",
      "for idx, document in enumerate(documents):\n",
      "    URL = \"http://localhost:9200/my_library/example/%s\" % (idx + 1)\n",
      "    print URL\n",
      "    print document\n",
      "    resp = requests.put(URL, data=json.dumps(document))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "http://localhost:9200/my_library/example/1\n",
        "{'title': 'apple apple apple apple apple'}\n",
        "http://localhost:9200/my_library/example/2\n",
        "{'title': 'apple apple apple banana banana'}\n",
        "http://localhost:9200/my_library/example/3\n",
        "{'title': 'apple banana blueberry coconut'}\n",
        "http://localhost:9200/my_library/example/4"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "{'title': 'apples apple'}\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "search = { \"explain\": \"true\",\n",
      "  \"query\": {\n",
      "    \"match\": {\n",
      "      \"title\": \"apple\"}}}\n",
      "\n",
      "resp = requests.get(\"http://localhost:9200/my_library/example/_search?pretty=true\", data=json.dumps(search))\n",
      "respJson = json.loads(resp.text)\n",
      "for hit in respJson['hits']['hits']:\n",
      "    print hit['_source']\n",
      "    print simplerExplain(hit['_explanation'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{u'title': u'apple apple apple apple apple'}\n",
        "0.75998294, sum of:\n",
        "  0.75998294, weight(title:appl in 0) [PerFieldSimilarity], result of:\n",
        "    0.75998294, fieldWeight in 0, product of:\n",
        "      2.236068, tf(freq=5.0), with freq of:\n",
        "        5.0, termFreq=5.0\n",
        "      0.7768564, idf(docFreq=4, maxDocs=4)\n",
        "      0.4375, fieldNorm(doc=0)\n",
        "  0.0, match on required clause, product of:\n",
        "    0.0, # clause\n",
        "    1.2872392, _type:example, product of:\n",
        "      1.0, boost\n",
        "      1.2872392, queryNorm\n",
        "\n",
        "{u'title': u'apples apple'}\n",
        "0.6866506, sum of:\n",
        "  0.6866506, weight(title:appl in 3) [PerFieldSimilarity], result of:\n",
        "    0.6866506, fieldWeight in 3, product of:\n",
        "      1.4142135, tf(freq=2.0), with freq of:\n",
        "        2.0, termFreq=2.0\n",
        "      0.7768564, idf(docFreq=4, maxDocs=4)\n",
        "      0.625, fieldNorm(doc=3)\n",
        "  0.0, match on required clause, product of:\n",
        "    0.0, # clause\n",
        "    1.2872392, _type:example, product of:\n",
        "      1.0, boost\n",
        "      1.2872392, queryNorm\n",
        "\n",
        "{u'title': u'apple apple apple banana banana'}\n",
        "0.58868027, sum of:\n",
        "  0.58868027, weight(title:appl in 1) [PerFieldSimilarity], result of:\n",
        "    0.58868027, fieldWeight in 1, product of:\n",
        "      1.7320508, tf(freq=3.0), with freq of:\n",
        "        3.0, termFreq=3.0\n",
        "      0.7768564, idf(docFreq=4, maxDocs=4)\n",
        "      0.4375, fieldNorm(doc=1)\n",
        "  0.0, match on required clause, product of:\n",
        "    0.0, # clause\n",
        "    1.2872392, _type:example, product of:\n",
        "      1.0, boost\n",
        "      1.2872392, queryNorm\n",
        "\n",
        "{u'title': u'apple banana blueberry coconut'}\n",
        "0.3884282, sum of:\n",
        "  0.3884282, weight(title:appl in 2) [PerFieldSimilarity], result of:\n",
        "    0.3884282, fieldWeight in 2, product of:\n",
        "      1.0, tf(freq=1.0), with freq of:\n",
        "        1.0, termFreq=1.0\n",
        "      0.7768564, idf(docFreq=4, maxDocs=4)\n",
        "      0.5, fieldNorm(doc=2)\n",
        "  0.0, match on required clause, product of:\n",
        "    0.0, # clause\n",
        "    1.2872392, _type:example, product of:\n",
        "      1.0, boost\n",
        "      1.2872392, queryNorm\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "search = { \"explain\": \"true\",\n",
      "  \"query\": {\n",
      "    \"match\": {\n",
      "      \"title\": \"apple banana\"}}}\n",
      "\n",
      "resp = requests.get(\"http://localhost:9200/my_library/example/_search?pretty=true\", data=json.dumps(search))\n",
      "respJson = json.loads(resp.text)\n",
      "for idx, hit in enumerate(respJson['hits']['hits']):\n",
      "    print (\"%s.  \" % (idx + 1)) + repr(hit['_source'])\n",
      "    print simplerExplain(hit['_explanation'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1.  {u'title': u'apple apple apple banana banana'}\n",
        "0.9862758, sum of:\n",
        "  0.9862758, sum of:\n",
        "    0.30409503, weight(title:appl in 1) [PerFieldSimilarity], result of:\n",
        "      0.30409503, score(doc=1,freq=3.0), product of:\n",
        "        0.5165708, queryWeight, product of:\n",
        "          0.7768564, idf(docFreq=4, maxDocs=4)\n",
        "          0.6649502, queryNorm\n",
        "        0.58868027, fieldWeight in 1, product of:\n",
        "          1.7320508, tf(freq=3.0), with freq of:\n",
        "            3.0, termFreq=3.0\n",
        "          0.7768564, idf(docFreq=4, maxDocs=4)\n",
        "          0.4375, fieldNorm(doc=1)\n",
        "    0.68218076, weight(title:banana in 1) [PerFieldSimilarity], result of:\n",
        "      0.68218076, score(doc=1,freq=2.0), product of:\n",
        "        0.85624444, queryWeight, product of:\n",
        "          1.287682, idf(docFreq=2, maxDocs=4)\n",
        "          0.6649502, queryNorm\n",
        "        0.79671264, fieldWeight in 1, product of:\n",
        "          1.4142135, tf(freq=2.0), with freq of:\n",
        "            2.0, termFreq=2.0\n",
        "          1.287682, idf(docFreq=2, maxDocs=4)\n",
        "          0.4375, fieldNorm(doc=1)\n",
        "  0.0, match on required clause, product of:\n",
        "    0.0, # clause\n",
        "    0.6649502, _type:example, product of:\n",
        "      1.0, boost\n",
        "      0.6649502, queryNorm\n",
        "\n",
        "2.  {u'title': u'apple banana blueberry coconut'}\n",
        "0.751936, sum of:\n",
        "  0.751936, sum of:\n",
        "    0.20065068, weight(title:appl in 2) [PerFieldSimilarity], result of:\n",
        "      0.20065068, score(doc=2,freq=1.0), product of:\n",
        "        0.5165708, queryWeight, product of:\n",
        "          0.7768564, idf(docFreq=4, maxDocs=4)\n",
        "          0.6649502, queryNorm\n",
        "        0.3884282, fieldWeight in 2, product of:\n",
        "          1.0, tf(freq=1.0), with freq of:\n",
        "            1.0, termFreq=1.0\n",
        "          0.7768564, idf(docFreq=4, maxDocs=4)\n",
        "          0.5, fieldNorm(doc=2)\n",
        "    0.5512853, weight(title:banana in 2) [PerFieldSimilarity], result of:\n",
        "      0.5512853, score(doc=2,freq=1.0), product of:\n",
        "        0.85624444, queryWeight, product of:\n",
        "          1.287682, idf(docFreq=2, maxDocs=4)\n",
        "          0.6649502, queryNorm\n",
        "        0.643841, fieldWeight in 2, product of:\n",
        "          1.0, tf(freq=1.0), with freq of:\n",
        "            1.0, termFreq=1.0\n",
        "          1.287682, idf(docFreq=2, maxDocs=4)\n",
        "          0.5, fieldNorm(doc=2)\n",
        "  0.0, match on required clause, product of:\n",
        "    0.0, # clause\n",
        "    0.6649502, _type:example, product of:\n",
        "      1.0, boost\n",
        "      0.6649502, queryNorm\n",
        "\n",
        "3.  {u'title': u'apple apple apple apple apple'}\n",
        "0.1962925, sum of:\n",
        "  0.1962925, product of:\n",
        "    0.392585, sum of:\n",
        "      0.392585, weight(title:appl in 0) [PerFieldSimilarity], result of:\n",
        "        0.392585, score(doc=0,freq=5.0), product of:\n",
        "          0.5165708, queryWeight, product of:\n",
        "            0.7768564, idf(docFreq=4, maxDocs=4)\n",
        "            0.6649502, queryNorm\n",
        "          0.75998294, fieldWeight in 0, product of:\n",
        "            2.236068, tf(freq=5.0), with freq of:\n",
        "              5.0, termFreq=5.0\n",
        "            0.7768564, idf(docFreq=4, maxDocs=4)\n",
        "            0.4375, fieldNorm(doc=0)\n",
        "    0.5, coord(1/2)\n",
        "  0.0, match on required clause, product of:\n",
        "    0.0, # clause\n",
        "    0.6649502, _type:example, product of:\n",
        "      1.0, boost\n",
        "      0.6649502, queryNorm\n",
        "\n",
        "4.  {u'title': u'apples apple'}\n",
        "0.17735182, sum of:\n",
        "  0.17735182, product of:\n",
        "    0.35470363, sum of:\n",
        "      0.35470363, weight(title:appl in 3) [PerFieldSimilarity], result of:\n",
        "        0.35470363, score(doc=3,freq=2.0), product of:\n",
        "          0.5165708, queryWeight, product of:\n",
        "            0.7768564, idf(docFreq=4, maxDocs=4)\n",
        "            0.6649502, queryNorm\n",
        "          0.6866506, fieldWeight in 3, product of:\n",
        "            1.4142135, tf(freq=2.0), with freq of:\n",
        "              2.0, termFreq=2.0\n",
        "            0.7768564, idf(docFreq=4, maxDocs=4)\n",
        "            0.625, fieldNorm(doc=3)\n",
        "    0.5, coord(1/2)\n",
        "  0.0, match on required clause, product of:\n",
        "    0.0, # clause\n",
        "    0.6649502, _type:example, product of:\n",
        "      1.0, boost\n",
        "      0.6649502, queryNorm\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}