{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import requests\n",
      "from httpcache import CachingHTTPAdapter\n",
      "import json\n",
      "import os\n",
      "import pickle\n",
      "from time import sleep\n",
      "\n",
      "# You might be running elasticsearch in a vagrant box\n",
      "esUrl = elasticSearchUrl = \"http://es:9200\"\n",
      "\n",
      "# you'll need to have an API key for TMDB\n",
      "# to run these examples,\n",
      "# run export TMDB_API_KEY=<YourAPIKey>\n",
      "tmdb_api_key = os.environ[\"TMDB_API_KEY\"]\n",
      "\n",
      "# Setup tmdb as its own session, caching requests\n",
      "# (we only want to cache tmdb, not elasticsearch)\n",
      "tmdb_api = requests.Session()\n",
      "tmdb_api.mount('https://', CachingHTTPAdapter())\n",
      "tmdb_api.mount('http://', CachingHTTPAdapter())\n",
      "tmdb_api.params={'api_key': tmdb_api_key}\n",
      "\n",
      "# Some utilities for flattening the explain into something a bit more\n",
      "# readable\n",
      "def flatten(l):\n",
      "    [item for sublist in l for item in sublist]\n",
      "\n",
      "def simplerExplain(explainJson, depth=0):\n",
      "    print explainJson['description']\n",
      "    result = \" \" * (depth * 2) + \"%s, %s\\n\" % (explainJson['value'], explainJson['description'])\n",
      "    #print json.dumps(explainJson, indent=True)\n",
      "    if 'details' in explainJson:\n",
      "        for detail in explainJson['details']:\n",
      "            result += simplerExplain(detail, depth=depth+1)\n",
      "    return result"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here we crawl top rated movies from TMDB and pull out a list of of top rated ids"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "movieIds = [];\n",
      "numMoviesToGrab = 10000\n",
      "numPages = numMoviesToGrab / 20\n",
      "\n",
      "for page in range(1, numPages + 1):\n",
      "    httpResp = tmdb_api.get('https://api.themoviedb.org/3/movie/top_rated', params={'page': page})  #(1)\n",
      "    jsonResponse = json.loads(httpResp.text) #(2)\n",
      "    movies = jsonResponse['results']\n",
      "    for movie in movies:\n",
      "        if (movie['id'] not in [9549]):\n",
      "            movieIds.append(movie['id'])\n",
      "print len(movieIds)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2859\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/home/doug/workspace/taming-search-book/scraps/venv/lib/python2.7/site-packages/requests/packages/urllib3/util/ssl_.py:79: InsecurePlatformWarning: A true SSLContext object is not available. This prevents urllib3 from configuring SSL appropriately and may cause certain SSL connections to fail. For more information, see https://urllib3.readthedocs.org/en/latest/security.html#insecureplatformwarning.\n",
        "  InsecurePlatformWarning\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "movieDict = {}\n",
      "for movieId in movieIds:\n",
      "    httpResp = tmdb_api.get(\"https://api.themoviedb.org/3/movie/%s\" % movieId)\n",
      "    movie = json.loads(httpResp.text)\n",
      "    movieDict[movieId] = movie"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Destroy any existing index (equiv to SQL \"drop table\")\n",
      "resp = requests.delete(elasticSearchUrl + \"/tmdb\")\n",
      "print resp.status_code\n",
      "\n",
      "# Create the index with explicit settings\n",
      "# We need to explicitely set number of shards to 1 to eliminate the impact of \n",
      "# distributed IDF on our small collection\n",
      "# See also \"Relavance is Broken!\"\n",
      "# http://www.elastic.co/guide/en/elasticsearch/guide/current/relevance-is-broken.html\n",
      "settings = {\n",
      "    \"settings\": {\"number_of_shards\": 1}\n",
      "}\n",
      "resp = requests.put(elasticSearchUrl + \"/tmdb\", data=json.dumps(settings))\n",
      "print resp.status_code\n",
      "\n",
      "# Bulk index title & overview to the movie endpoint\n",
      "print \"Indexing %i movies\" % len(movieDict.keys())\n",
      "bulkMovies = \"\"\n",
      "for id, movie in movieDict.iteritems():\n",
      "    addCmd = {\"index\": {\"_index\": \"tmdb\", \"_type\": \"movie\", \"_id\": movie[\"id\"]}}\n",
      "    esDoc  = {\"title\": movie['title'], 'overview': movie['overview'], 'tagline': movie['tagline']}\n",
      "    bulkMovies += json.dumps(addCmd) + \"\\n\" + json.dumps(esDoc) + \"\\n\"\n",
      "requests.post(elasticSearchUrl + \"/_bulk\", data=bulkMovies)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "200\n",
        "200"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Indexing 2846 movies\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 12,
       "text": [
        "<Response [200]>"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Execute a fairly basic search\n",
      "# Where many may start, obviously title matches are important, but our\n",
      "# body field (overview) also should get a great deal of weight\n",
      "# \n",
      "# PROBLEM\n",
      "#  This query is replete with problems\n",
      "#   - with probably should be a stopword (yet it causes the title results with 'with') to shoot to the top\n",
      "#   - even after fixing this, we see that dismax \"winner takes all\" creates problems\n",
      "# \n",
      "#\n",
      "# Multi Match notes\n",
      "#   starts out like dismax\n",
      "#   type dictates how dismax is handled\n",
      "#    - default best_fields is winner takes all problems with dismax\n",
      "#    - most_fields (like dismax with tie always set to 1 -- Doug's favorite)\n",
      "#       Every field gets a vote\n",
      "#    - cross fields (unique to ES)\n",
      "#\n",
      "usersSearch = 'basketball with cartoon aliens'\n",
      "search = {\n",
      "    'query': {\n",
      "        'multi_match': { \n",
      "            'query': usersSearch,  #User's query\n",
      "            'fields': ['title^10', 'overview'],\n",
      "        }\n",
      "    },\n",
      "    'size': '100'\n",
      "}\n",
      "\n",
      "httpResp = requests.get(elasticSearchUrl + '/tmdb/movie/_search', data=json.dumps(search))\n",
      "searchHits = json.loads(httpResp.text)['hits']\n",
      "print \"Num\\tRelevance Score\\t\\tMovie Title\\t\\tOverview\"\n",
      "for idx, hit in enumerate(searchHits['hits']):\n",
      "    print \"%s\\t%s\\t\\t%s\\t\\t%s\" % (idx + 1, hit['_score'], hit['_source']['title'], hit['_source']['overview'][:20])\n",
      "\n",
      "# print searchHits['hits'][0]['_source']['overview']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Num\tRelevance Score\t\tMovie Title\t\tOverview\n",
        "1\t0.8424165\t\tAliens\t\tWhen Ripley's lifepo\n",
        "2\t0.5603433\t\tThe Basketball Diaries\t\tFilm adaptation of s\n",
        "3\t0.52651036\t\tCowboys & Aliens\t\tA stranger stumbles \n",
        "4\t0.42120826\t\tAliens vs Predator: Requiem\t\tA sequel to 2004's A\n",
        "5\t0.42120826\t\tAliens in the Attic\t\tIt's summer vacation\n",
        "6\t0.42120826\t\tMonsters vs Aliens\t\tWhen Susan Murphy is\n",
        "7\t0.262869\t\tDances with Wolves\t\tWounded Civil War so\n",
        "8\t0.262869\t\tInterview with the Vampire\t\tA vampire relates hi\n",
        "9\t0.262869\t\tFrom Russia With Love\t\tJames Bond is back a\n",
        "10\t0.262869\t\tGone with the Wind\t\tAn American classic \n",
        "11\t0.262869\t\tFriends with Benefits\t\tWhile trying to avoi\n",
        "12\t0.262869\t\tJust Go With It\t\tIn Just Go With It, \n",
        "13\t0.262869\t\tFire with Fire\t\tA fireman takes an u\n",
        "14\t0.262869\t\tMy Week with Marilyn\t\tSir Laurence Olivier\n",
        "15\t0.262869\t\tFrom Paris with Love\t\tWhile working at the\n",
        "16\t0.262869\t\tTrouble with the Curve\t\tSlowed by age and fa\n",
        "17\t0.262869\t\tFriends with Kids\t\tRevolves around a pa\n",
        "18\t0.262869\t\tTo Rome with Love\t\tSet in the romantic \n",
        "19\t0.23001038\t\tDie Hard: With a Vengeance\t\tNew York detective J\n",
        "20\t0.23001038\t\tGirl with a Pearl Earring\t\tThis film, adapted f\n",
        "21\t0.23001038\t\tFun with Dick and Jane\t\tAfter losing their h\n",
        "22\t0.19715175\t\tThe Girl with the Dragon Tattoo\t\tThis English-languag\n",
        "23\t0.19715175\t\tThe Life Aquatic With Steve Zissou\t\tWes Anderson\u2019s incis\n",
        "24\t0.19715175\t\tTwin Peaks: Fire Walk with Me\t\tTwin Peaks: Fire Wal\n",
        "25\t0.19715175\t\tYou Don't Mess With the Zohan\t\tAn Israeli counterte\n",
        "26\t0.19715175\t\tCloudy with a Chance of Meatballs 2\t\tAfter the disastrous\n",
        "27\t0.19715175\t\tThe Man with the Golden Gun\t\tA golden bullet has \n",
        "28\t0.19715175\t\tCloudy with a Chance of Meatballs\t\tInventor Flint Lockw\n",
        "29\t0.19715175\t\tThe Pirates! In an Adventure with Scientists!\t\tIn The Pirates! Band\n",
        "30\t0.19715175\t\tThe Girl with the Dragon Tattoo\t\tSwedish thriller bas\n",
        "31\t0.19715175\t\tThe Man with the Iron Fists\t\tIn feudal China, a b\n",
        "32\t0.19715175\t\tThe Girl Who Played with Fire\t\tMikael Blomkvist, pu\n",
        "33\t0.031565353\t\tMeet Dave\t\tA crew of miniature \n",
        "34\t0.02688633\t\tSpeed Racer\t\tSpeed racer is the t\n",
        "35\t0.021973845\t\tSemi-Pro\t\tJackie Moon is the o\n",
        "36\t0.02095456\t\tBedazzled\t\tElliot Richardson, s\n",
        "37\t0.018953558\t\tDistrict 9\t\tAliens land in South\n",
        "38\t0.018310659\t\tThe Watch\t\tFour everyday suburb\n",
        "39\t0.018310659\t\tAlien: Resurrection\t\tTwo hundred years af\n",
        "40\t0.016977157\t\tSpace Jam\t\tMichael Jordan agree\n",
        "41\t0.016021827\t\tThey Live\t\tNada, a down-on-his-\n",
        "42\t0.01455185\t\tGrown Ups\t\tAfter their high sch\n",
        "43\t0.014215169\t\tMen in Black 3\t\tAgents J (Will Smith\n",
        "44\t0.012667119\t\tThe Flintstones\t\tModern Stone Age fam\n",
        "45\t0.012126542\t\tWhite Men Can't Jump\t\tBilly Hoyle (Woody H\n",
        "46\t0.012126542\t\tCoach Carter\t\tBased on a true stor\n",
        "47\t0.010474103\t\tGalaxy Quest\t\tDecades after the su\n",
        "48\t0.008488579\t\tHigh School Musical\t\tTroy (Zac Efron), th\n",
        "49\t0.008379282\t\tAVP: Alien vs. Predator\t\tWhen scientists disc\n",
        "50\t0.008379282\t\tPitch Black\t\tAfter crash-landing \n",
        "51\t0.0073318724\t\tBattlefield Earth\t\tIn the year 3000, ma\n",
        "52\t0.0073318724\t\tDude, Where\u2019s My Car?\t\tJesse and Chester, t\n",
        "53\t0.0019206188\t\tSex Drive\t\tA high school senior\n",
        "54\t0.0016801915\t\tDark City\t\tA man struggles with\n",
        "55\t0.0016462447\t\tSilver Linings Playbook\t\tAfter spending eight\n",
        "56\t0.0016462447\t\tStrangers on a Train\t\tA psychotic socialit\n",
        "57\t0.0016462447\t\tNim's Island\t\tA young girl inhabit\n",
        "58\t0.0016462447\t\tThe Guard\t\tAn unorthodox Irish \n",
        "59\t0.0016462447\t\t[REC]\u00b2\t\tThe action continues\n",
        "60\t0.0016462447\t\tCinema Paradiso\t\tA filmmaker recalls \n",
        "61\t0.0016462447\t\tWild Card\t\tWhen a Las Vegas bod\n",
        "62\t0.0016462447\t\tBride of Chucky\t\tChucky hooks up with\n",
        "63\t0.0016462447\t\tSafe Haven\t\tA young woman with a\n",
        "64\t0.0016462447\t\tYoung Adult\t\tA divorced writer fr\n",
        "65\t0.0016462447\t\tOdd Thomas\t\tIn a California dese\n",
        "66\t0.0015520945\t\tAdam's Apples\t\tA neo-nazi sentenced\n",
        "67\t0.0015520945\t\tTeenage Mutant Ninja Turtles\t\tA quartet of mutated\n",
        "68\t0.0015520945\t\tCrash\t\tLos Angeles citizens\n",
        "69\t0.0015520945\t\tShallow Hal\t\tA shallow man falls \n",
        "70\t0.0015520945\t\tBecoming Jane\t\tA biographical portr\n",
        "71\t0.0015520945\t\tBandits\t\tTwo bank robbers fal\n",
        "72\t0.0015520945\t\tFantasia 2000\t\tAn update of the ori\n",
        "73\t0.0015520945\t\tThe Curious Case of Benjamin Button\t\tTells the story of B\n",
        "74\t0.0015520945\t\tDesperado\t\tA gunslinger is embr\n",
        "75\t0.0013718706\t\t8\u00bd\t\tWith 8 \u00bd Frederico F\n",
        "76\t0.0013718706\t\tCharlie's Angels: Full Throttle\t\tThe Angels are charg\n",
        "77\t0.0013718706\t\tGhost World\t\tA quirky girl tries \n",
        "78\t0.0013718706\t\tJust Friends\t\tWhile visiting his h\n",
        "79\t0.0013718706\t\tStuart Little\t\tThe adventures of a \n",
        "80\t0.0013718706\t\tFantastic Mr. Fox\t\tThe Fantastic Mr. Fo\n",
        "81\t0.0013718706\t\tLady and the Tramp\t\tLady, a golden cocke\n",
        "82\t0.0013718706\t\tOutlander\t\tDuring the reign of \n",
        "83\t0.0013718706\t\tTrance\t\tA fine art auctionee\n",
        "84\t0.0013718706\t\tStep Up Revolution\t\tEmily arrives in Mia\n",
        "85\t0.0013718706\t\tRobin Hood\t\tWith King Richard of\n",
        "86\t0.0013718706\t\tThe Graduate\t\tRecent college gradu\n",
        "87\t0.0013718706\t\tMy Big Fat Greek Wedding\t\tA young Greek woman \n",
        "88\t0.0013718706\t\tStoker\t\tAfter India's father\n",
        "89\t0.0013718706\t\tHowl's Moving Castle\t\tWhen Sophie, a shy y\n",
        "90\t0.0013718706\t\tVicky Cristina Barcelona\t\tTwo girlfriends on a\n",
        "91\t0.0013718706\t\tMesrine: Killer Instinct\t\tThe early career (19\n",
        "92\t0.0013718706\t\t27 Dresses\t\tAfter serving as a b\n",
        "93\t0.0013718706\t\tRust and Bone\t\tPut in charge of his\n",
        "94\t0.0013718706\t\tSubmarine\t\t15-year-old deep-thi\n",
        "95\t0.0013718706\t\tThe Spiderwick Chronicles\t\tUpon moving into the\n",
        "96\t0.0013580826\t\tSin City: A Dame to Kill For\t\tSome of Sin City's m\n",
        "97\t0.0013580826\t\tSpider-Man\t\tAfter being bitten b\n",
        "98\t0.0013580826\t\tThe French Connection\t\tA pair of NYC cops i\n",
        "99\t0.0013580826\t\tFrida\t\t\"Frida\" chronicles t\n",
        "100\t0.0013580826\t\tThe Virgin Suicides\t\tA group of male frie\n"
       ]
      }
     ],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Inner Layer of the Onion -- Why did the search engine consider these movies matches? Two sides to this\n",
      "# (1) What tokens are placed in the search engine?\n",
      "# (2) What did the search engine attempt to match exactly?\n",
      "\n",
      "# Explain of what's happening when we construct these terms\n",
      "\n",
      "resp = requests.get(elasticSearchUrl + \"/tmdb/_mapping/movie/field/title?format=yaml\n",
      "resp = requests.get(elasticSearchUrl + '/tmdb/_analyze?analyzer=standard&format=yaml', \n",
      "                    data=\"The Lego Movie An ordinary Lego mini-figure, mistakenly\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "SyntaxError",
       "evalue": "EOL while scanning string literal (<ipython-input-117-5e72ab43f690>, line 7)",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-117-5e72ab43f690>\"\u001b[0;36m, line \u001b[0;32m7\u001b[0m\n\u001b[0;31m    resp = requests.get(elasticSearchUrl + \"/tmdb/_mapping/movie/field/title?format=yaml\u001b[0m\n\u001b[0m                                                                                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m EOL while scanning string literal\n"
       ]
      }
     ],
     "prompt_number": 117
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Explain what's happening behind the scenes in this multimatch query\n",
      "\n",
      "just_search = {\n",
      "   'query': {\n",
      "        'multi_match': { \n",
      "            'query': usersSearch,  #User's query\n",
      "            'fields': ['title^10', 'overview']\n",
      "        }\n",
      "    }\n",
      "}\n",
      "httpResp = requests.get(elasticSearchUrl + '/tmdb/movie/_validate/query?explain', data=json.dumps(just_search))\n",
      "json.loads(httpResp.text)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 10,
       "text": [
        "{u'_shards': {u'failed': 0, u'successful': 1, u'total': 1},\n",
        " u'explanations': [{u'explanation': u'filtered((((title:basketball title:with title:cartoon title:aliens)^10.0) | (overview:basketball overview:with overview:cartoon overview:aliens)))->cache(_type:movie)',\n",
        "   u'index': u'tmdb',\n",
        "   u'valid': True}],\n",
        " u'valid': True}"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# The explain shows us there is a clear problem with ambigous terms\n",
      "# What is one way to solve this?\n",
      "#  - We have a genre field we could introduce\n",
      "#  - Can we curate a set of synonyms (ie 'space exploration') as synonymous with\n",
      "#    a particular genre?\n",
      "\n",
      "search['explain'] = True\n",
      "httpResp = requests.get(elasticSearchUrl + '/tmdb/movie/_search', data=json.dumps(search))\n",
      "jsonResp = json.loads(httpResp.text)\n",
      "print \"Explain for %s\" % jsonResp['hits']['hits'][0]['_source']['title']\n",
      "print simplerExplain(jsonResp['hits']['hits'][0]['_explanation'])\n",
      "print \"Explain for %s\" % jsonResp['hits']['hits'][1]['_source']['title']\n",
      "print simplerExplain(jsonResp['hits']['hits'][1]['_explanation'])\n",
      "print \"Explain for %s\" % jsonResp['hits']['hits'][2]['_source']['title']\n",
      "print simplerExplain(jsonResp['hits']['hits'][3]['_explanation'])\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Explain for The Amazing Spider-Man\n",
        "max of:\n",
        "product of:\n",
        "sum of:\n",
        "weight(title:amazing in 1665) [PerFieldSimilarity], result of:\n",
        "score(doc=1665,freq=1.0 = termFreq=1.0\n",
        "), product of:\n",
        "queryWeight, product of:\n",
        "idf(docFreq=2, maxDocs=2846)\n",
        "queryNorm\n",
        "fieldWeight in 1665, product of:\n",
        "tf(freq=1.0), with freq of:\n",
        "termFreq=1.0\n",
        "idf(docFreq=2, maxDocs=2846)\n",
        "fieldNorm(doc=1665)\n",
        "coord(1/2)\n",
        "1.29507, max of:\n",
        "  1.29507, product of:\n",
        "    2.59014, sum of:\n",
        "      2.59014, weight(title:amazing in 1665) [PerFieldSimilarity], result of:\n",
        "        2.59014, score(doc=1665,freq=1.0 = termFreq=1.0\n",
        "), product of:\n",
        "          0.65948343, queryWeight, product of:\n",
        "            7.8550577, idf(docFreq=2, maxDocs=2846)\n",
        "            0.08395653, queryNorm\n",
        "          3.9275289, fieldWeight in 1665, product of:\n",
        "            1.0, tf(freq=1.0), with freq of:\n",
        "              1.0, termFreq=1.0\n",
        "            7.8550577, idf(docFreq=2, maxDocs=2846)\n",
        "            0.5, fieldNorm(doc=1665)\n",
        "    0.5, coord(1/2)\n",
        "\n",
        "Explain for The Amazing Spider-Man 2\n",
        "max of:\n",
        "product of:\n",
        "sum of:\n",
        "weight(title:amazing in 1894) [PerFieldSimilarity], result of:\n",
        "score(doc=1894,freq=1.0 = termFreq=1.0\n",
        "), product of:\n",
        "queryWeight, product of:\n",
        "idf(docFreq=2, maxDocs=2846)\n",
        "queryNorm\n",
        "fieldWeight in 1894, product of:\n",
        "tf(freq=1.0), with freq of:\n",
        "termFreq=1.0\n",
        "idf(docFreq=2, maxDocs=2846)\n",
        "fieldNorm(doc=1894)\n",
        "coord(1/2)\n",
        "1.1331863, max of:\n",
        "  1.1331863, product of:\n",
        "    2.2663727, sum of:\n",
        "      2.2663727, weight(title:amazing in 1894) [PerFieldSimilarity], result of:\n",
        "        2.2663727, score(doc=1894,freq=1.0 = termFreq=1.0\n",
        "), product of:\n",
        "          0.65948343, queryWeight, product of:\n",
        "            7.8550577, idf(docFreq=2, maxDocs=2846)\n",
        "            0.08395653, queryNorm\n",
        "          3.4365878, fieldWeight in 1894, product of:\n",
        "            1.0, tf(freq=1.0), with freq of:\n",
        "              1.0, termFreq=1.0\n",
        "            7.8550577, idf(docFreq=2, maxDocs=2846)\n",
        "            0.4375, fieldNorm(doc=1894)\n",
        "    0.5, coord(1/2)\n",
        "\n",
        "Explain for Spider-Man\n",
        "max of:\n",
        "product of:\n",
        "sum of:\n",
        "weight(overview:amazing in 1068) [PerFieldSimilarity], result of:\n",
        "score(doc=1068,freq=1.0 = termFreq=1.0\n",
        "), product of:\n",
        "queryWeight, product of:\n",
        "idf(docFreq=5, maxDocs=2846)\n",
        "queryNorm\n",
        "fieldWeight in 1068, product of:\n",
        "tf(freq=1.0), with freq of:\n",
        "termFreq=1.0\n",
        "idf(docFreq=5, maxDocs=2846)\n",
        "fieldNorm(doc=1068)\n",
        "coord(1/2)\n",
        "0.02691487, max of:\n",
        "  0.02691487, product of:\n",
        "    0.05382974, sum of:\n",
        "      0.05382974, weight(overview:amazing in 1068) [PerFieldSimilarity], result of:\n",
        "        0.05382974, score(doc=1068,freq=1.0 = termFreq=1.0\n",
        "), product of:\n",
        "          0.060128916, queryWeight, product of:\n",
        "            7.1619105, idf(docFreq=5, maxDocs=2846)\n",
        "            0.008395653, queryNorm\n",
        "          0.8952388, fieldWeight in 1068, product of:\n",
        "            1.0, tf(freq=1.0), with freq of:\n",
        "              1.0, termFreq=1.0\n",
        "            7.1619105, idf(docFreq=5, maxDocs=2846)\n",
        "            0.125, fieldNorm(doc=1068)\n",
        "    0.5, coord(1/2)\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 65
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "---\n",
        "tmdb:\n",
        "  settings:\n",
        "    index:\n",
        "      creation_date: \"1423513692064\"\n",
        "      uuid: \"m8A_tI3gSi6QBG-6fZsUBQ\"\n",
        "      number_of_replicas: \"1\"\n",
        "      number_of_shards: \"5\"\n",
        "      version:\n",
        "        created: \"1040299\"\n",
        "\n",
        "---\n",
        "tmdb:\n",
        "  mappings:\n",
        "    movie:\n",
        "      title:\n",
        "        full_name: \"title\"\n",
        "        mapping:\n",
        "          title:\n",
        "            type: \"string\"\n",
        "\n",
        "---\n",
        "tokens:\n",
        "- token: \"the\"\n",
        "  start_offset: 0\n",
        "  end_offset: 3\n",
        "  type: \"<ALPHANUM>\"\n",
        "  position: 1\n",
        "- token: \"lego\"\n",
        "  start_offset: 4\n",
        "  end_offset: 8\n",
        "  type: \"<ALPHANUM>\"\n",
        "  position: 2\n",
        "- token: \"movie\"\n",
        "  start_offset: 9\n",
        "  end_offset: 14\n",
        "  type: \"<ALPHANUM>\"\n",
        "  position: 3\n",
        "- token: \"an\"\n",
        "  start_offset: 15\n",
        "  end_offset: 17\n",
        "  type: \"<ALPHANUM>\"\n",
        "  position: 4\n",
        "- token: \"ordinary\"\n",
        "  start_offset: 18\n",
        "  end_offset: 26\n",
        "  type: \"<ALPHANUM>\"\n",
        "  position: 5\n",
        "- token: \"lego\"\n",
        "  start_offset: 27\n",
        "  end_offset: 31\n",
        "  type: \"<ALPHANUM>\"\n",
        "  position: 6\n",
        "- token: \"mini\"\n",
        "  start_offset: 32\n",
        "  end_offset: 36\n",
        "  type: \"<ALPHANUM>\"\n",
        "  position: 7\n",
        "- token: \"figure\"\n",
        "  start_offset: 37\n",
        "  end_offset: 43\n",
        "  type: \"<ALPHANUM>\"\n",
        "  position: 8\n",
        "- token: \"mistakenly\"\n",
        "  start_offset: 45\n",
        "  end_offset: 55\n",
        "  type: \"<ALPHANUM>\"\n",
        "  position: 9\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Removing Domain-Specific Stopwords"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To reduce the impact of the movie term, one thing we can try is to list movie itself as a stopword. A stopword is a term considered noise. It tends corresponds to an absense of meaning. Articles like \"the\" and prepositions like \"of\" are common candidates in most English stopwords lists. Usually stopwords are known for their very high document frequency and therefore low impact on the score. So we often don't need to do anything to the stopwords.\n",
      "\n",
      "However, occasionally we encounter domain-specific stopwords so obvious that they are often omitted from the text. We saw this for the \"movie\" term above. The feature of \"movieness\" is heavily implied, and not at all reflected in the text. These scenarios are particularly true for shorter snippets of text where brevity rules the day. Much of our current text is rather short, so our movie search suffers from these problems.\n",
      "\n",
      "We need to express to the search engine that the term \"movie\" should be removed from the index. To do this, we need to create a custom analyzer, using the current standard analyzer as its basis. We'll then assign the `_all` field to this analyzer via the mapping API."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "requests.delete(esUrl + '/tmdb')\n",
      "\n",
      "settings = {\n",
      "    'settings': {\n",
      "        \"number_of_shards\": 1,\n",
      "        'analysis': {\n",
      "            'analyzer': {\n",
      "                'movie_text': {\n",
      "                    'type': 'standard',\n",
      "                    'stopwords': ['movie'],\n",
      "                }\n",
      "            }\n",
      "        },\n",
      "        'analyzer': 'movie_text',       \n",
      "    },\n",
      "    'mappings': {\n",
      "            'movie': {\n",
      "                '_all': {\n",
      "                    'type': 'string',\n",
      "                    'analyzer': 'movie_text',\n",
      "                }\n",
      "            }\n",
      "       }\n",
      "    \n",
      "}\n",
      "\n",
      "#requests.post(esUrl + \"/tmdb/_close\")\n",
      "resp = requests.put(esUrl + '/tmdb/', data=json.dumps(settings))\n",
      "print resp.text\n",
      "sleep(1)\n",
      "\n",
      "\n",
      "resp = requests.get(esUrl + '/tmdb/_mappings?format=yaml')\n",
      "print resp.text\n",
      "#requests.post(esUrl + \"/tmdb/_open\")\n",
      "print resp.text\n",
      "# Wait for index to open\n",
      "\n",
      "sleep(1)\n",
      "\n",
      "# Reindex\n",
      "resp = requests.post(elasticSearchUrl + \"/_bulk\", data=bulkMovies)\n",
      "\n",
      "resp = requests.get(elasticSearchUrl + '/tmdb/_analyze?field=_all&format=yaml', \n",
      "                    data=\"The Lego Movie An ordinary Lego mini-figure, mistakenly\")\n",
      "print resp.text\n",
      "\n",
      "resp = requests.get(elasticSearchUrl + '/tmdb/_refresh')\n",
      "print resp.text\n",
      "\n",
      "sleep(1)\n",
      "\n",
      "search = {\n",
      "    'explain': 'true',\n",
      "    'query': {\n",
      "        'match': { \n",
      "            '_all': 'space exploration movie'  #User's query\n",
      "        }\n",
      "    }\n",
      "}\n",
      "httpResp = requests.get(elasticSearchUrl + '/tmdb/movie/_search', data=json.dumps(search))\n",
      "searchHits = json.loads(httpResp.text)['hits']\n",
      "\n",
      "print \"Relevance Score\\t\\tMovie Title\\t\\tOverview\"\n",
      "for hit in searchHits['hits']:\n",
      "    print \"%s\\t\\t%s\\t\\t%s\" % (hit['_score'], hit['_source']['title'], hit['_source']['overview'][:50])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{\"acknowledged\":true}\n",
        "---\n",
        "tmdb:\n",
        "  mappings:\n",
        "    movie:\n",
        "      _all:\n",
        "        analyzer: \"movie_text\"\n",
        "      properties: {}\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "---\n",
        "tmdb:\n",
        "  mappings:\n",
        "    movie:\n",
        "      _all:\n",
        "        analyzer: \"movie_text\"\n",
        "      properties: {}\n",
        "\n",
        "---\n",
        "tokens:\n",
        "- token: \"the\"\n",
        "  start_offset: 0\n",
        "  end_offset: 3\n",
        "  type: \"<ALPHANUM>\"\n",
        "  position: 1\n",
        "- token: \"lego\"\n",
        "  start_offset: 4\n",
        "  end_offset: 8\n",
        "  type: \"<ALPHANUM>\"\n",
        "  position: 2\n",
        "- token: \"an\"\n",
        "  start_offset: 15\n",
        "  end_offset: 17\n",
        "  type: \"<ALPHANUM>\"\n",
        "  position: 4\n",
        "- token: \"ordinary\"\n",
        "  start_offset: 18\n",
        "  end_offset: 26\n",
        "  type: \"<ALPHANUM>\"\n",
        "  position: 5\n",
        "- token: \"lego\"\n",
        "  start_offset: 27\n",
        "  end_offset: 31\n",
        "  type: \"<ALPHANUM>\"\n",
        "  position: 6\n",
        "- token: \"mini\"\n",
        "  start_offset: 32\n",
        "  end_offset: 36\n",
        "  type: \"<ALPHANUM>\"\n",
        "  position: 7\n",
        "- token: \"figure\"\n",
        "  start_offset: 37\n",
        "  end_offset: 43\n",
        "  type: \"<ALPHANUM>\"\n",
        "  position: 8\n",
        "- token: \"mistakenly\"\n",
        "  start_offset: 45\n",
        "  end_offset: 55\n",
        "  type: \"<ALPHANUM>\"\n",
        "  position: 9\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "{\"_shards\":{\"total\":2,\"successful\":1,\"failed\":0}}\n",
        "Relevance Score\t\tMovie Title\t\tOverview"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.1524828\t\tThe Man from Earth\t\tAn impromptu goodbye party for Professor John Oldm\n",
        "0.1524828\t\tInterstellar\t\tInterstellar chronicles the adventures of a group \n",
        "0.13477701\t\tGravity\t\tDr. Ryan Stone (Sandra Bullock), a brilliant medic\n",
        "0.13342245\t\tSolaris\t\tGround control has been receiving strange transmis\n"
       ]
      }
     ],
     "prompt_number": 117
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}